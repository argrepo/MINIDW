#######################################################################################
############## Clearing the Plots and existing Objects
#######################################################################################
options(repos=structure(c(CRAN="https://cran.rstudio.com/")))

cores <- parallel::detectCores()

options(Ncpus = cores)

pdf(NULL)

rm(list=ls())

##########################################################################

#################################################################
##################### Input Parameters
#################################################################
############## DB Connectivity Parameters #########

args <- commandArgs(TRUE)

parameter_file_name <- args[1]


#param_input <- read.csv("param.csv",header=TRUE,stringsAsFactors = FALSE)

##### Reading the Parameter File
param_input <- read.csv(parameter_file_name,header=TRUE,stringsAsFactors = FALSE)

print("Preview of the Parameter File")
print(param_input)

client <- as.character(param_input$VALUE[param_input$PARAM=="client"])
app_db_host <- as.character(param_input$VALUE[param_input$PARAM=="app_db_host"])
app_db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="app_db_port"]))
app_db_name <- as.character(param_input$VALUE[param_input$PARAM=="app_db_name"])
app_db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="app_db_user_name"])
app_db_password <- as.character(param_input$VALUE[param_input$PARAM=="app_db_password"])
staging_db_host <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_host"])
staging_db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="staging_db_port"]))
staging_db_name <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_name"])
staging_db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_user_name"])
staging_db_password <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_password"])
db_host <- as.character(param_input$VALUE[param_input$PARAM=="db_host"])
db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="db_port"]))
db_name <- as.character(param_input$VALUE[param_input$PARAM=="db_name"])
db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="db_user_name"])
db_password <- as.character(param_input$VALUE[param_input$PARAM=="db_password"])
log_file_path <- as.character(param_input$VALUE[param_input$PARAM=="log_file_path"])
user_defined_functions_path <- as.character(param_input$VALUE[param_input$PARAM=="user_defined_functions_path"])
#user_defined_functions_path <- "/usr/_MINIDW/AIJOBS/AI_COMMON_JOBS/"

################## Model Specific Parameters ###########################

Business_Problem <- as.character(param_input$VALUE[param_input$PARAM=="Business Problem"])
Model_Name <- as.character(param_input$VALUE[param_input$PARAM=="Model Name"])
model_start_year <- 2015
model_start_month <- 1
model_data_frequency <- as.integer(param_input$VALUE[param_input$PARAM=="model_data_frequency"])
current_year <- as.integer(param_input$VALUE[param_input$PARAM=="current_year"])
differencing_order <- as.integer(param_input$VALUE[param_input$PARAM=="differencing_order"])
desired_forecast_period <- as.integer(param_input$VALUE[param_input$PARAM=="desired_forecast_period"])
data_points_criteria <- as.integer(param_input$VALUE[param_input$PARAM=="data_points_criteria"])

#model_end_year <- year(Sys.time())-1
model_end_year <- 2017
model_end_month <- 12
#current_year <- year(Sys.time())
current_year <- 2018
#current_month <- month(Sys.time())
current_month <- as.integer(param_input$VALUE[param_input$PARAM=="current_month"])

###################################################################################
######################## Creating a Log File with the entire console execution
#############################################################################################

timestamp <- gsub(pattern=" ","",gsub(pattern = "[[:punct:]]","",as.character(Sys.time())))

log_file_name <- paste(client,"_",gsub(pattern = " ","_",Business_Problem),'_',gsub(pattern = " ","_",Model_Name),"_",timestamp,".log",sep="")

#### Sinking the console output to the Log File
sink(paste(log_file_path,"/",log_file_name,sep=""))

print(paste0("Log File Name: ",log_file_name,sep=""))

#### Capturing the start time of the code execution

start_time <- Sys.time()


####################################################################################
###################### Installing the required Packages and loading the libraries
#################################################################################

if(!require("nnfor")) install.packages("nnfor"); library("nnfor")
if(!require("DMwR")) install.packages("DMwR"); library("DMwR")
if(!require("plyr")) install.packages("plyr"); library("plyr")
if(!require("DBI")) install.packages("DBI"); library("DBI")
if(!require("RMySQL")) install.packages("RMySQL"); library("RMySQL")
if(!require("dplyr")) install.packages("dplyr"); library("dplyr")
if(!require("forecast")) install.packages("forecast"); library("forecast")
if(!require("sqldf")) install.packages("sqldf"); library("sqldf")
if(!require("data.table")) install.packages("data.table"); library("data.table")
if(!require("forecast")) install.packages("forecast"); library("forecast")
if(!require("readr")) install.packages("readr"); library("readr")
if(!require("Metrics")) install.packages("Metrics"); library("Metrics")
if(!require("smooth")) install.packages("smooth"); library("smooth")
if(!require("mice")) install.packages("mice"); library("mice")
if(!require("stringr")) install.packages("stringr", type="source"); library("stringr")
if(!require("outliers")) install.packages("outliers"); library("outliers")
#if(!require("foreach")) install.packages("stringr", type="source"); library("foreach")
#if(!require("doParallel")) install.packages("doParallel", type="source"); library("doParallel")

###################### Setting the default options #################

###### setting default driver of sqldf library to SQLite
options(sqldf.driver = "SQLite")

###### Turning off the scientific Notation of Numbers
options(scipen = 999)

##################################################################################
############# Load the user defined functions ##################
##################################################################################

source(paste0(user_defined_functions_path,"connect_mysql_db.R",sep=""))
source(paste0(user_defined_functions_path,"get_AI_Model_Metadata.R",sep=""))
source(paste0(user_defined_functions_path,"staging_data_load.R",sep=""))
source(paste0(user_defined_functions_path,"data_quality_report.R",sep=""))
source(paste0(user_defined_functions_path,"missing_data_pattern_report.R",sep=""))
source(paste0(user_defined_functions_path,"numerical_data_summary_report.R",sep=""))
source(paste0(user_defined_functions_path,"string_data_summary_report.R",sep=""))
#source(paste0(user_defined_functions_path,"basic_data_summary_report.R",sep=""))
source(paste0(user_defined_functions_path,"random_forest_imputation.R",sep=""))
source(paste0(user_defined_functions_path,"data_outliers_impute.R",sep=""))

############################################################################
############### Connecting to the managaeDB Database
#############################################################################

mysql_db_connection <- connect_mysql_db(db_host,db_port,db_name,db_user_name,db_password)
mysql_staging_db_connection <- connect_mysql_db(staging_db_host,staging_db_port,staging_db_name,
                                                staging_db_user_name,staging_db_password)
mysql_app_db_connection <- connect_mysql_db(app_db_host,app_db_port,app_db_name,app_db_user_name,app_db_password)

##################################################################################
#################### Updating the AI Job Execution Summary 
##################################################################################

AI_Job_RUN_ID <- dbGetQuery(mysql_staging_db_connection,"select max(RUN_ID) from AI_Jobs_Execution_Summary")

new_AI_Job_RUN_ID <- if(is.na(AI_Job_RUN_ID)){1}else{AI_Job_RUN_ID+1}

dbSendQuery(mysql_staging_db_connection,paste0("insert into AI_Jobs_Execution_Summary(
                                               RUN_ID,BUSINESS_PROBLEM,AI_MODEL,JOB_START_DATETIME,JOB_RUN_STATUS,JOB_LOG_FILENAME)
                                               VALUES(",
                                               new_AI_Job_RUN_ID,",",
                                               "'",Business_Problem,"',",
                                               "'",Model_Name,"',",
                                               "'",start_time,"'",",",
                                               "'","Started","'",",",
                                               "'",log_file_name,"')",
                                               sep=""))

############################################################################
############### Getting the AI Metadata
#############################################################################

AI_Metadata_Details <- get_AI_Model_Metadata(mysql_app_db_connection,Business_Problem,Model_Name)

############################################################################
############### Loading Source Data into Staging Table
#############################################################################

staging_sql <- as.character(AI_Metadata_Details$in_staging_sql_query)

staging_table_name <- as.character(AI_Metadata_Details$STAGING_TABLE)

source_records <- staging_data_load(mysql_staging_db_connection,mysql_db_connection,staging_sql,staging_table_name)

##################################################################################
#################### Updating the AI Job Execution Summary 
##################################################################################

dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                               SET SOURCE_RECORD_COUNT=",
                                               source_records,
                                               " , JOB_RUN_STATUS=",
                                               "'","Source Data Reading Completed","'",
                                               " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))

############################################################################
########### Conditional Execution of AI Model
############################################################################

if(exists("source_records") & source_records>0){
  
  print(paste0("Source Query Result set contains: ",source_records,sep=""))
  
  ############################################################################
  ############### Displaying the Source Data Summary Report
  #############################################################################
  
  data_quality_report(mysql_staging_db_connection,staging_table_name)
  
  ############################################################################
  ############### Applying Statistical Transformations
  #############################################################################
  
  staging_data <- dbGetQuery(mysql_staging_db_connection,paste0("select * from ",staging_table_name,sep=""))
  
  staging_records <- nrow(staging_data)
  
  ##################################################################################
  #################### Updating the AI Job Execution Summary 
  ##################################################################################
  
  dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                                 SET STAGING_RECORD_COUNT=",
                                                 staging_records,
                                                 " , JOB_RUN_STATUS=",
                                                 "'","Staging Load Completed","'",
                                                 " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
  
  
  ################### Transforming the staging Data
  
  transformed_data <- suppressWarnings(random_forest_imputation(staging_data,4,1234))
  
  ail_data <- transformed_data
  
  ail_table_name <- as.character(AI_Metadata_Details$AIL_TABLE)
  
  ######################### Loading the AIL Table ######################################
  #### Checking the count of records for transformed_data and then proceeding
  #### with loading the transformed_data into AIL Table
  
  
  if(exists("ail_data") & nrow(ail_data)>0){
    
    #### Truncating the AIL Table
    #### Right now, insert and update option of data loading is not implemented
    
    dbSendQuery(mysql_db_connection,paste0("truncate table ",ail_table_name,sep=""))
    
    #################### Looping through the entire data set to create the insert statements
    
    for(i in 1:nrow(ail_data)){
      
      dbSendQuery(mysql_db_connection,paste0("insert into ",ail_table_name, "(
                                             DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                                             YEAR,MONTH,ACTUAL_SALES) ",
                                             "values(",
                                             "\"",ail_data$DIMENSION1[i],"\"",",",
                                             "\"",ail_data$DIMENSION2[i],"\"",",",
                                             "\"",ail_data$DIMENSION3[i],"\"",",",
                                             "\"",ail_data$DIMENSION4[i],"\"",",",
                                             "\"",ail_data$DIMENSION5[i],"\"",",",
                                             ail_data$YEAR[i],",",ail_data$MONTH[i],",",
                                             ail_data$ACTUAL_SALES[i],")",sep="")) } 
    
    ########################### End of the Looping to insert the records into AIL Table
    
    print("Transformed Data Successfully Loaded into AIL Table")
    
    ##################################################################################
    #################### Updating the AI Job Execution Summary 
    ##################################################################################
    
    ail_record_count <- dbGetQuery(mysql_db_connection,"select count(1) from AIL_Sales_Forecast")
    
    dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                                 SET AIL_RECORD_COUNT=",
                                                   ail_record_count,
                                                   " , JOB_RUN_STATUS=",
                                                   "'","AIL Data Load Completed","'",
                                                   " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
    
  } else {
    
    print("AIL Table Data Load Failed. Please check the Staging Data or the Transformations")
    
  }
  
  
  #### Selecting the previous years Data and records having non zero sales in 2018
  
  transformed_data <- sqldf("select * from transformed_data where YEAR!=2018
                            union select * from transformed_data
                            where ACTUAL_SALES!= 0 and YEAR=2018")
  
    ##################### Dimensional Analysis and Loading it into AI_DP_Analysis Table
    
    ##########  Analyzing the combination of dimensions for data criteria 
    ###################################################
    
    #### Function to get unique records in the dimensions
    
    unique_rows <- function(input){
      if(sum(str_length(input))==0 &
         length(is.na(input))==length(input)) {
        unique_rows <- 0
      } else {
        unique_rows <- length(unique(input))
      }
    }
    
    ############################### End of the Function 
    
    Dimension_Analysis <- as.data.frame(apply(transformed_data[,1:5],2,unique_rows))
    column <- row.names(Dimension_Analysis)
    row.names(Dimension_Analysis) <- NULL
    Dimension_Analysis <- cbind(column,Dimension_Analysis)
    colnames(Dimension_Analysis) <- c("DIMENSION","UNIQUE_VALUES")
    
    
    print("Analyzing the Combination of Dimensions")
    print(Dimension_Analysis)
    valid_dimensions <- filter(Dimension_Analysis,UNIQUE_VALUES>0)
    print(paste("Dimensions having one or more unique values are: ", 
                paste(valid_dimensions$DIMENSION,collapse = ","),sep=""))
    
    
    #####################################################################################
    
    Dim_Data_Analysis <- sqldf("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                               max(YEAR) as MAX_YEAR, 
                               min(YEAR) as MIN_YEAR, count(*) as TOTAL_DATA_POINTS
                               from transformed_data 
                               group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5")
    
    Dim_Data_Analysis_historical <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                count(*) as HISTORICAL_DATA_POINTS
                                                from transformed_data
                                                where YEAR!=",current_year," 
                                                group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    Dim_Data_Analysis_historical_Sales <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                      sum(ACTUAL_SALES) as HISTORICAL_SALES
                                                      from transformed_data
                                                      where YEAR!=",current_year," 
                                                      group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    
    Dim_Data_Analysis_Current_Year <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                  count(*) as DATA_POINTS_CURRENT_YEAR
                                                  from transformed_data
                                                  where YEAR=",current_year," 
                                                  group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    
    Dim_Data_Analysis_last2_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_2_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_last3_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_3_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,",",current_year-3,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_last4_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_4_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,",",current_year-3,
                                                 ",",current_year-4,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_CYMM <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                          max(MONTH) as CURRENT_YEAR_MAX_MONTH
                                          from transformed_data
                                          where YEAR==",current_year," 
                                          group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",
                                          sep=""))
    
    
    Dim_Data_Analysis_Combined <- sqldf("select x.*, y.HISTORICAL_DATA_POINTS,
                                        e.HISTORICAL_SALES,
                                        a.DATA_POINTS_PAST_2_YEARS,
                                        b.DATA_POINTS_PAST_3_YEARS,
                                        c.DATA_POINTS_PAST_4_YEARS,
                                        z.DATA_POINTS_CURRENT_YEAR,
                                        d.CURRENT_YEAR_MAX_MONTH
                                        from Dim_Data_Analysis x
                                        left outer join Dim_Data_Analysis_historical y
                                        on (x.DIMENSION1=y.DIMENSION1 and
                                        x.DIMENSION2=y.DIMENSION2 and
                                        x.DIMENSION3=y.DIMENSION3 and
                                        x.DIMENSION4=y.DIMENSION4 and 
                                        x.DIMENSION5=y.DIMENSION5)
                                        left outer join Dim_Data_Analysis_historical_Sales e
                                        on (x.DIMENSION1=e.DIMENSION1 and
                                        x.DIMENSION2=e.DIMENSION2 and
                                        x.DIMENSION3=e.DIMENSION3 and
                                        x.DIMENSION4=e.DIMENSION4 and 
                                        x.DIMENSION5=e.DIMENSION5)
                                        left outer join Dim_Data_Analysis_Current_Year z
                                        on (x.DIMENSION1=z.DIMENSION1 and
                                        x.DIMENSION2=z.DIMENSION2 and
                                        x.DIMENSION3=z.DIMENSION3 and
                                        x.DIMENSION4=z.DIMENSION4 and 
                                        x.DIMENSION5=z.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last2_years a
                                        on (x.DIMENSION1=a.DIMENSION1 and
                                        x.DIMENSION2=a.DIMENSION2 and
                                        x.DIMENSION3=a.DIMENSION3 and
                                        x.DIMENSION4=a.DIMENSION4 and 
                                        x.DIMENSION5=a.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last3_years b
                                        on (x.DIMENSION1=b.DIMENSION1 and
                                        x.DIMENSION2=b.DIMENSION2 and
                                        x.DIMENSION3=b.DIMENSION3 and
                                        x.DIMENSION4=b.DIMENSION4 and 
                                        x.DIMENSION5=b.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last4_years c
                                        on (x.DIMENSION1=c.DIMENSION1 and
                                        x.DIMENSION2=c.DIMENSION2 and
                                        x.DIMENSION3=c.DIMENSION3 and
                                        x.DIMENSION4=c.DIMENSION4 and 
                                        x.DIMENSION5=c.DIMENSION5)
                                        left outer join  Dim_Data_Analysis_CYMM d
                                        on (x.DIMENSION1=d.DIMENSION1 and
                                        x.DIMENSION2=d.DIMENSION2 and
                                        x.DIMENSION3=d.DIMENSION3 and
                                        x.DIMENSION4=d.DIMENSION4 and 
                                        x.DIMENSION5=d.DIMENSION5)"
    )
    
    ### Removing the temp objects of dim analysis
    rm(Dim_Data_Analysis,Dim_Data_Analysis_Current_Year,Dim_Data_Analysis_historical,
       Dim_Data_Analysis_historical_Sales,
       Dim_Data_Analysis_last2_years,Dim_Data_Analysis_last3_years,
       Dim_Data_Analysis_last4_years, Dim_Data_Analysis_CYMM)
    
    ### Replacing NAs with Zero
    Dim_Data_Analysis_Combined[is.na(Dim_Data_Analysis_Combined)] <- 0 
    
    ## Checking the valid combinations of the Dimensions
    Valid_Data <- subset(Dim_Data_Analysis_Combined,
                         Dim_Data_Analysis_Combined$TOTAL_DATA_POINTS>=data_points_criteria & 
                           Dim_Data_Analysis_Combined$MAX_YEAR==current_year &
                           Dim_Data_Analysis_Combined$DATA_POINTS_PAST_2_YEARS==24 &
                           Dim_Data_Analysis_Combined$HISTORICAL_SALES>0)
    
    Invalid_Data <- subset(Dim_Data_Analysis_Combined,
                           Dim_Data_Analysis_Combined$TOTAL_DATA_POINTS<data_points_criteria | 
                             Dim_Data_Analysis_Combined$MAX_YEAR!=current_year |
                             Dim_Data_Analysis_Combined$DATA_POINTS_PAST_2_YEARS<24 |
                             Dim_Data_Analysis_Combined$HISTORICAL_SALES<=0)
    
    Invalid_Data$RULE1 <- ifelse(Invalid_Data$TOTAL_DATA_POINTS<data_points_criteria, 1, 0)
    Invalid_Data$RULE2 <- ifelse(Invalid_Data$MAX_YEAR!=current_year, 1, 0)
    Invalid_Data$RULE3 <- ifelse(Invalid_Data$DATA_POINTS_PAST_2_YEARS<24, 1, 0)
    Invalid_Data$RULE4 <- ifelse(Invalid_Data$HISTORICAL_SALES<=0, 1, 0)
    
    ### Framing the Validation Rules Table

    RULE <- c(paste("TDP < ",data_points_criteria,sep=""),paste("Max Year != ",current_year,sep=""),
              "DP Last 2 Years < 24","Historical Sales <= 0")
    
    RULE_NAME <- c("RULE1","RULE2","RULE3","RULE4")
    
    RULE_DESCRIPTION <- c("TOTAL DATA POINTS < DATA POINTS CRITERIA","MAX YEAR != CURRENT_YEAR",
                          "DATA POINTS IN LAST 2 YEARS","SUM OF HISTORICAL SALES (Zero,Negative)")
    
    validation_rules_master <- as.data.frame(cbind(RULE,RULE_NAME,RULE_DESCRIPTION))
    
    if(exists("validation_rules_master") & nrow(validation_rules_master)>0){
      
      print("Loading the Validation Rules into DB Table")
      
      #### Looping through the validation Rules and creating insert statements
      
       dbSendQuery(mysql_db_connection,"truncate table AI_Sales_Forecast_Validation_Rules")
      
        for(i in 1:nrow(validation_rules_master)) {
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_Validation_Rules",
                                               "(ID,RULE_NAME,RULE_DESCRIPTION,RULE) ",
                                               "values(",i,",",
                                               "'",validation_rules_master$RULE_NAME[i],"'",",",
                                               "'",validation_rules_master$RULE_DESCRIPTION[i],"'",",",
                                               "'",validation_rules_master$RULE[i],"'",
                                               ")",sep=""))}
      
      print("Data Loading into Validation Rules Table is completed Successfully") 
      
    } else {
      
      print("No Validation Rules Data")
      
    }

  
    ### Printing the count of Valid and Invalid combinations of Dimensions
    print(paste0("Valid Combinations of Dimensions for Forecasting: ",nrow(Valid_Data),sep=""))
    
    print(paste0("Invalid Combinations of Dimensions for Forecasting: ",nrow(Dim_Data_Analysis_Combined)-nrow(Valid_Data),sep=""))
    print("Check the Data Analysis Table for more information")
    
    #######################################################################################
    ############# Writing the Valid and Invalid Dimension - Data Criteria Check
    ######################################################################################
    
    if(exists("Valid_Data") & nrow(Valid_Data)>0){
      
      print("Loading the Sales Forecast Valid Data Points Analysis into DB Table")
      
      #### Looping through the DP Analysis and creating insert statements
      
      #### Getting the RUN_ID from the table
      
      DP_Analysis_Valid_RUN_ID <- dbGetQuery(mysql_db_connection,
                                             "select max(RUN_ID) from AI_Sales_Forecast_Validation_DP_Valid")
      
      new_DP_Analysis_Valid_RUN_ID <- if(is.na(DP_Analysis_Valid_RUN_ID)){1}else{DP_Analysis_Valid_RUN_ID+1}
      
      
      for(i in 1:nrow(Valid_Data)) {
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_Validation_DP_Valid",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,MAX_YEAR,MIN_YEAR,TOTAL_DATA_POINTS,
                                               HISTORICAL_DATA_POINTS,HISTORICAL_SALES,
                                               DATA_POINTS_LAST_2_YEARS,
                                               DATA_POINTS_LAST_3_YEARS,DATA_POINTS_LAST_4_YEARS,
                                               DATA_POINTS_CURRENT_YEAR,CURRENT_YEAR_MAX_MONTH) ",
                                               "values(",new_DP_Analysis_Valid_RUN_ID,",",
                                               "'",Valid_Data$DIMENSION1[i],"'",",",
                                               "'",Valid_Data$DIMENSION2[i],"'",",",
                                               "'",Valid_Data$DIMENSION3[i],"'",",",
                                               "'",Valid_Data$DIMENSION4[i],"'",",",
                                               "'",Valid_Data$DIMENSION5[i],"'",",",
                                               Valid_Data$MAX_YEAR[i],",",
                                               Valid_Data$MIN_YEAR[i],",",
                                               Valid_Data$TOTAL_DATA_POINTS[i],",",
                                               Valid_Data$HISTORICAL_DATA_POINTS[i],",",
                                               Valid_Data$HISTORICAL_SALES[i],",",
                                               Valid_Data$DATA_POINTS_PAST_2_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_PAST_3_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_PAST_4_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_CURRENT_YEAR[i],",",
                                               Valid_Data$CURRENT_YEAR_MAX_MONTH[i],
                                               ")",sep=""))}
      
      print("Data Loading into Valid Data Points Analysis Table is completed Successfully") 
      
    } else {
      
      print("Error Occured in Dimensional Data Analysis/No Valid Data Points")
      print("Please check the Transformed Data Object")
      
    }
    
    
    if(exists("Invalid_Data") & nrow(Invalid_Data)>0){
      
      print("Loading the Sales Forecast Invalid Data Points Analysis into DB Table")
      
      #### Looping through the DP Analysis and creating insert statements
      
      #### Getting the RUN_ID from the table
      
      DP_Analysis_Invalid_RUN_ID <- dbGetQuery(mysql_db_connection,
                                               "select max(RUN_ID) from AI_Sales_Forecast_Validation_DP_Invalid")
      
      new_DP_Analysis_Invalid_RUN_ID <- if(is.na(DP_Analysis_Invalid_RUN_ID)){1}else{DP_Analysis_Invalid_RUN_ID+1}
      
      
      for(i in 1:nrow(Invalid_Data)){
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_Validation_DP_Invalid",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,MAX_YEAR,MIN_YEAR,TOTAL_DATA_POINTS,
                                               HISTORICAL_DATA_POINTS,HISTORICAL_SALES,
                                               DATA_POINTS_LAST_2_YEARS,
                                               DATA_POINTS_LAST_3_YEARS,DATA_POINTS_LAST_4_YEARS,
                                               DATA_POINTS_CURRENT_YEAR,CURRENT_YEAR_MAX_MONTH,
                                               RULE1,RULE2,RULE3,RULE4) ",
                                               "values(",new_DP_Analysis_Invalid_RUN_ID,",",
                                               "'",Invalid_Data$DIMENSION1[i],"'",",",
                                               "'",Invalid_Data$DIMENSION2[i],"'",",",
                                               "'",Invalid_Data$DIMENSION3[i],"'",",",
                                               "'",Invalid_Data$DIMENSION4[i],"'",",",
                                               "'",Invalid_Data$DIMENSION5[i],"'",",",
                                               Invalid_Data$MAX_YEAR[i],",",
                                               Invalid_Data$MIN_YEAR[i],",",
                                               Invalid_Data$TOTAL_DATA_POINTS[i],",",
                                               Invalid_Data$HISTORICAL_DATA_POINTS[i],",",
                                               Invalid_Data$HISTORICAL_SALES[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_2_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_3_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_4_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_CURRENT_YEAR[i],",",
                                               Invalid_Data$CURRENT_YEAR_MAX_MONTH[i],",",
                                               Invalid_Data$RULE1[i],",",
                                               Invalid_Data$RULE2[i],",",
                                               Invalid_Data$RULE3[i],",",
                                               Invalid_Data$RULE4[i],
                                               ")",sep=""))}
      
      ##### End of Data Loading Looping
      print("Data Loading into Invalid Data Points Analysis Table is completed Successfully") 
      
    } else {
      
      print("Error Occured in Dimensional Data Analysis/No Invalid Data Points")
      print("Please check the Transformed Data Object")
      
    }
    
    ##################################################################################################
    ####################### Sales Forecast Models Validation for Dimensional Combinations ##############
    #################################################################################################
    
    ##### Assigning the list objects for various SF Models
    
    list.sales_forecast_arima <- list()
    
    list.sales_forecast_nnmlp <- list()
    
    list.sales_forecast_ets <- list()
    
    list.sales_forecast_sma <- list()
    
    list.sales_forecast_holtwinters <- list()
    
    list.sales_forecast_recommended <- list()
    
    list.sales_forecast_validation <- list()
    
    list.sales_forecast_models_mape <- list()
    
    ###### Looping through every combination of valid Data Combination 
    
    ### Registering the Parallel System
    
    #registerDoParallel()
    
    system.time(for(i in 1:nrow(Valid_Data))
      
    {
      
      ###### Dynamically checking the availability of DP
      ##### finding out the start year for each combination
      
      if(Valid_Data$DATA_POINTS_PAST_4_YEARS[i]==48){
        valid_start_year <- current_year-4
      } else if (Valid_Data$DATA_POINTS_PAST_3_YEARS[i]==36) {
        valid_start_year <- current_year-3
      } else if (Valid_Data$DATA_POINTS_PAST_2_YEARS[i]==24){
        valid_start_year <- current_year-2
      } else {
        valid_start_year <- NULL
      }
      
      #### Start Year Check Completed
      
      x_dimension1 <- Valid_Data$DIMENSION1[i]
      x_dimension2 <- Valid_Data$DIMENSION2[i]
      x_dimension3 <- Valid_Data$DIMENSION3[i]
      x_dimension4 <- Valid_Data$DIMENSION4[i]
      x_dimension5 <- Valid_Data$DIMENSION5[i]
      x_current_year_max_month <- Valid_Data$CURRENT_YEAR_MAX_MONTH[i]
      
      
      x_data <- subset(transformed_data,(transformed_data$DIMENSION1==x_dimension1 &
                                           transformed_data$DIMENSION2==x_dimension2 &
                                           transformed_data$DIMENSION3==x_dimension3 &
                                           transformed_data$DIMENSION4==x_dimension4 &
                                           transformed_data$DIMENSION5==x_dimension5 &
                                           transformed_data$YEAR>=valid_start_year))
      
      ### Filtering the train and validation data from the entire data
      
      x_train_data <- filter(x_data,x_data$YEAR!=current_year)
      
      #### Imputing any Zero Values with Median
      
      x_train_data$ACTUAL_SALES[x_train_data$ACTUAL_SALES==0] <- median(x_train_data$ACTUAL_SALES)
      
      ### Imputing the outliers with Median
      
      x_train_data$ACTUAL_SALES <- data_outliers_impute(x_train_data$ACTUAL_SALES,"median")
      
      #### Checking whether the data contains zero or Negative Values
      
      if(nrow(filter(x_train_data,ACTUAL_SALES==0 | ACTUAL_SALES<0))==0) {
        
        x_train_data$ACTUAL_SALES <- log1p(x_train_data$ACTUAL_SALES)
        
        flag_zero_negative <- 0
        
      } else {
        
        ### Finding the constant value to add to handle zero and Negative Values
        
        constant_value <- abs(min(x_train_data$ACTUAL_SALES))+0.0001
        
        #### Adding the constant Value to all the Sales Amount
        
        x_train_data$ACTUAL_SALES <- x_train_data$ACTUAL_SALES+constant_value
        
        #### Applying Log Transformation to the Sales Amount
        
        x_train_data$ACTUAL_SALES <- log1p(x_train_data$ACTUAL_SALES)
        
        flag_zero_negative <- 1
        
      }
      
      ### Getting the current_data
      
      x_current_data <- filter(x_data,x_data$YEAR==current_year)
      
      ### Creating the time series object
      
      data.ts <- ts(x_train_data$ACTUAL_SALES,start=c(valid_start_year,01),end=c(current_year-1,12),frequency = 12)
      
      ## Plotting the time series object
      
      #plot(data.ts)
      ## Fitting a straight Line
      #abline(reg=lm(data.ts~time(data.ts)))
      #Plotting the decomposition of Time series
      #(Seasonal, Trend and Irregular components)
      #plot(decompose(data.ts))
      #out_decompose <- decompose(data.ts)
      #Add_multiply_type <- out_decompose$type
      #print(paste("The type of model(Additive/Multiplicative):",Add_multiply_type ))
      
      ### Cycle across the years
      #cycle(data.ts)
      #aggregate the cycles and display a year on year trend
      #plot(aggregate(data.ts,FUN=mean))
      #Plotting the differences in the time series to make it stationary
      #diff(data.ts)
      #differenced_time_series <- diff(data.ts, differences = 2)
      #plot(differenced_time_series)
      
      #######################################################################
      ############################ Building the Arima Model
      ##########################################################################
      
      arima.model <- auto.arima(data.ts,stationary = FALSE, seasonal = FALSE)
      
      #summary(arima.model)
      #### Calculating the new forecast period to accomodate the validation and customer desired forecast period
      
      new_desired_forecast_period <- x_current_year_max_month
      
      predicted_data <- forecast(arima.model,new_desired_forecast_period)
      
      ## Plotting the predicted Values
      #plot(predicted_data)
      
      #autoplot(predicted_data)
      arima_method <- predicted_data$method
      
      ### creating the Forecast Method Variable
      
      FORECAST_METHOD <- data.frame(rep('AUTO ARIMA',new_desired_forecast_period))
      colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      
      ### Creating the Dimensions variables
      
      DIMENSION1 <- rep(x_dimension1,new_desired_forecast_period)
      DIMENSION2 <- rep(x_dimension2,new_desired_forecast_period)
      DIMENSION3 <- rep(x_dimension3,new_desired_forecast_period)
      DIMENSION4 <- rep(x_dimension4,new_desired_forecast_period)
      DIMENSION5 <- rep(x_dimension5,new_desired_forecast_period)
      
      Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      
      ### Creating the Measures Variables
      
      PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data))
      YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
      MONTH <- substr(PREDICTED_PERIOD,1,3)
      
      x_predicted_data <- as.data.frame(predicted_data)
      
      FORECASTED_SALES <- as.numeric(x_predicted_data[,1])
      
      Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      
      ### Creatning the Final Data Frame
      
      Final_Data_arima <- cbind(Dimensions,Measures)
      
      ### Storing the Arima Method for every Combination
      #Final_Data_Arima_Method <- cbind(Dimensions[,-1],arima_method)
      
      ### Changing the MMM format to MM Format for Month
      
      Final_Data_arima <- sqldf("select FORECAST_METHOD,
                                DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                                YEAR,
                                case 
                                when MONTH='Jan' then 1
                                when MONTH='Feb' then 2
                                when MONTH='Mar' then 3
                                when MONTH='Apr' then 4
                                when MONTH='May' then 5
                                when MONTH='Jun' then 6
                                when MONTH='Jul' then 7
                                when MONTH='Aug' then 8
                                when MONTH='Sep' then 9
                                when MONTH='Oct' then 10
                                when MONTH='Nov' then 11
                                when MONTH='Dec' then 12
                                else MONTH end as MONTH,
                                cast(FORECASTED_SALES as decimal(38,16)) as FORECASTED_SALES
                                from Final_Data_arima")
      
      ### Back Transforming the output
      
      if(flag_zero_negative==0) {
        
        Final_Data_arima$FORECASTED_SALES <- expm1(as.numeric(as.character(
          Final_Data_arima$FORECASTED_SALES)))
      } else {
        
        Final_Data_arima$FORECASTED_SALES <- (expm1(as.numeric(as.character(
          Final_Data_arima$FORECASTED_SALES)))-constant_value)
        
      }
      
      row.names(Final_Data_arima) <- NULL
      
      list.sales_forecast_arima[[i]] <- Final_Data_arima
      
      #list.arima.method[[i]] <- arima_method
      
      #######################################################################################
      #########      Exponential Smoothing Method
      #######################################################################################
      
      ets_data.ts <- ets(data.ts, model="ZZZ", damped = NULL)
      
      #plot(ets_data.ts)
      #summary(ets_data.ts)
      
      predicted_data_ets <- forecast(ets_data.ts, new_desired_forecast_period)
      
      # Plotting the forecasted Data
      #plot(predicted_data_ets)
      #autoplot(predicted_data_ets)
      
      FORECAST_METHOD <- data.frame(rep('ETS',new_desired_forecast_period))
      
      colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      
      Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      
      PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_ets))
      YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
      MONTH <- substr(PREDICTED_PERIOD,1,3)
      
      x_predicted_data <- as.data.frame(predicted_data_ets)
      
      FORECASTED_SALES <- as.numeric(x_predicted_data[,1])
      
      Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      
      Final_Data_ets <- cbind(Dimensions,Measures)
      
      Final_Data_ets <- sqldf("select FORECAST_METHOD,
                              DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                              YEAR,
                              case 
                              when MONTH='Jan' then 1
                              when MONTH='Feb' then 2
                              when MONTH='Mar' then 3
                              when MONTH='Apr' then 4
                              when MONTH='May' then 5
                              when MONTH='Jun' then 6
                              when MONTH='Jul' then 7
                              when MONTH='Aug' then 8
                              when MONTH='Sep' then 9
                              when MONTH='Oct' then 10
                              when MONTH='Nov' then 11
                              when MONTH='Dec' then 12
                              else MONTH end as MONTH,FORECASTED_SALES
                              from Final_Data_ets")
      
      ### Back Transforming the output
      
      if(flag_zero_negative==0) {
        
        Final_Data_ets$FORECASTED_SALES <- expm1(as.numeric(as.character(
          Final_Data_ets$FORECASTED_SALES)))
      } else {
        
        Final_Data_ets$FORECASTED_SALES <- (expm1(as.numeric(as.character(
          Final_Data_ets$FORECASTED_SALES)))-constant_value)
        
      }
      
      row.names(Final_Data_ets) <- NULL
      
      list.sales_forecast_ets[[i]] <- Final_Data_ets
      
      ######################################################################################
      #######################################################################################
      #################### Simple Moving Average
      #######################################################################################
      
      sma_model <- sma(data.ts,h=new_desired_forecast_period)
      
      predicted_data_sma <- forecast(sma_model, new_desired_forecast_period)
      
      #plot(predicted_data_sma)
      
      FORECAST_METHOD <- data.frame(rep('SMA',new_desired_forecast_period))
      
      colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      
      Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      
      PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_sma))
      
      YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
      
      MONTH <- substr(PREDICTED_PERIOD,1,3)
      
      x_predicted_data <- as.data.frame(predicted_data_sma$mean)
      
      FORECASTED_SALES <- abs(as.numeric(x_predicted_data[,1]))
      
      Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      
      Final_Data_sma <- cbind(Dimensions,Measures)
      
      Final_Data_sma <- sqldf("select FORECAST_METHOD,
                              DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                              YEAR,
                              case 
                              when MONTH='Jan' then 1
                              when MONTH='Feb' then 2
                              when MONTH='Mar' then 3
                              when MONTH='Apr' then 4
                              when MONTH='May' then 5
                              when MONTH='Jun' then 6
                              when MONTH='Jul' then 7
                              when MONTH='Aug' then 8
                              when MONTH='Sep' then 9
                              when MONTH='Oct' then 10
                              when MONTH='Nov' then 11
                              when MONTH='Dec' then 12
                              else MONTH end as MONTH,FORECASTED_SALES
                              from Final_Data_sma")
      
      ### Back Transforming the output
      
      if(flag_zero_negative==0) {
        
        Final_Data_sma$FORECASTED_SALES <- expm1(as.numeric(as.character(
          Final_Data_sma$FORECASTED_SALES)))
      } else {
        
        Final_Data_sma$FORECASTED_SALES <- (expm1(as.numeric(as.character(
          Final_Data_sma$FORECASTED_SALES)))-constant_value)
        
      }
      
      
      row.names(Final_Data_sma) <- NULL
      
      list.sales_forecast_sma[[i]] <- Final_Data_sma
      
      
      #######################################################################################
      ############## Holts Winter Method with Seasonality
      #######################################################################################
      #beta=FALSE to facilitate the exponential smoothing
      
      holt_winters_model <- HoltWinters(data.ts)
      
      #summary(holt_winters_model)
      
      predicted_data_holtwinters <- forecast(holt_winters_model,new_desired_forecast_period)
      
      #plot(predicted_data_holtwinters)
      
      FORECAST_METHOD <- data.frame(rep('HOLT WINTERS',new_desired_forecast_period))
      
      colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      
      Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      
      PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_holtwinters))
      
      YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
      
      MONTH <- substr(PREDICTED_PERIOD,1,3)
      
      FORECASTED_SALES <- as.numeric(predicted_data_holtwinters$mean)
      
      Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      
      Final_Data_holtwinters <- cbind(Dimensions,Measures)
      
      Final_Data_holtwinters <- sqldf("select FORECAST_METHOD,
                                      DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                                      YEAR,
                                      case 
                                      when MONTH='Jan' then 1
                                      when MONTH='Feb' then 2
                                      when MONTH='Mar' then 3
                                      when MONTH='Apr' then 4
                                      when MONTH='May' then 5
                                      when MONTH='Jun' then 6
                                      when MONTH='Jul' then 7
                                      when MONTH='Aug' then 8
                                      when MONTH='Sep' then 9
                                      when MONTH='Oct' then 10
                                      when MONTH='Nov' then 11
                                      when MONTH='Dec' then 12
                                      else MONTH end as MONTH,FORECASTED_SALES
                                      from Final_Data_holtwinters")
      
      ### Back Transforming the output
      
      if(flag_zero_negative==0) {
        
        Final_Data_holtwinters$FORECASTED_SALES <- expm1(as.numeric(as.character(
          Final_Data_holtwinters$FORECASTED_SALES)))
      } else {
        
        Final_Data_holtwinters$FORECASTED_SALES <- (expm1(as.numeric(as.character(
          Final_Data_holtwinters$FORECASTED_SALES)))-constant_value)
        
      }
      
      
      row.names(Final_Data_holtwinters) <- NULL
      
      list.sales_forecast_holtwinters[[i]] <- Final_Data_holtwinters
      
      #######################################################################################
      ########################## Neural Networks - ETAR
      #######################################################################################
      
      ### estimation type is set to step -- stepwise regression with AIC
      ### input is given as actual time series object instead of differenced object
      ### since it will be handled in the model itself automatically
      
      # nnetar_model <- nnetar(data.ts,lambda = 0,p=11)
      # 
      # # Forecasting the Sales for n months
      # 
      # predicted_data <- forecast(nnetar_model,new_desired_forecast_period)
      # 
      # plot(predicted_data)
      # 
      # FORECAST_METHOD <- data.frame(rep('NN-ETAR',new_desired_forecast_period))
      # 
      # colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      # 
      # Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      # 
      # x_predicted_data <- as.data.frame(predicted_data$mean)
      # 
      # FORECASTED_SALES <- as.numeric(x_predicted_data$x)
      # 
      # Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      # 
      # Final_Data_nnetar <- cbind(Dimensions,Measures)
      # 
      # Final_Data_nnetar <- sqldf("select FORECAST_METHOD,
      #                            DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
      #                            YEAR,
      #                            case 
      #                            when MONTH='Jan' then 1
      #                            when MONTH='Feb' then 2
      #                            when MONTH='Mar' then 3
      #                            when MONTH='Apr' then 4
      #                            when MONTH='May' then 5
      #                            when MONTH='Jun' then 6
      #                            when MONTH='Jul' then 7
      #                            when MONTH='Aug' then 8
      #                            when MONTH='Sep' then 9
      #                            when MONTH='Oct' then 10
      #                            when MONTH='Nov' then 11
      #                            when MONTH='Dec' then 12
      #                            else MONTH end as MONTH,FORECASTED_SALES
      #                            from Final_Data_nnetar")
      # 
      # if(flag_zero_negative==0) {
      #   
      #   Final_Data_nnetar$FORECASTED_SALES <- expm1(as.numeric(as.character(
      #     Final_Data_nnetar$FORECASTED_SALES)))
      # } else {
      #   
      #   Final_Data_nnetar$FORECASTED_SALES <- (expm1(as.numeric(as.character(
      #     Final_Data_nnetar$FORECASTED_SALES)))-constant_value)
      #   
      # }
      # 
      # row.names(Final_Data_nnetar) <- NULL
      # 
      # list.sales_forecast_nnetar[[i]] <- Final_Data_nnetar
      
      #######################################################################################
      ##################### Neural Networks - MLP - Multi Layer Perceptron
      #######################################################################################
      
      nnmlp_model <- mlp(data.ts)
      
      predicted_data <- forecast(nnmlp_model,new_desired_forecast_period)
      
      #plot(predicted_data)
      
      FORECAST_METHOD <- data.frame(rep('NN-MLP',new_desired_forecast_period))
      
      colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
      
      Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
      
      x_predicted_data <- as.data.frame(predicted_data$mean)
      
      FORECASTED_SALES <- as.numeric(x_predicted_data$x)
      
      Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
      
      Final_Data_nnmlp <- cbind(Dimensions,Measures)
      
      Final_Data_nnmlp <- sqldf("select FORECAST_METHOD,
                                DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                                YEAR,
                                case 
                                when MONTH='Jan' then 1
                                when MONTH='Feb' then 2
                                when MONTH='Mar' then 3
                                when MONTH='Apr' then 4
                                when MONTH='May' then 5
                                when MONTH='Jun' then 6
                                when MONTH='Jul' then 7
                                when MONTH='Aug' then 8
                                when MONTH='Sep' then 9
                                when MONTH='Oct' then 10
                                when MONTH='Nov' then 11
                                when MONTH='Dec' then 12
                                else MONTH end as MONTH,FORECASTED_SALES
                                from Final_Data_nnmlp")
      
      if(flag_zero_negative==0) {
        
        Final_Data_nnmlp$FORECASTED_SALES <- expm1(as.numeric(as.character(
          Final_Data_nnmlp$FORECASTED_SALES)))
      } else {
        
        Final_Data_nnmlp$FORECASTED_SALES <- (expm1(as.numeric(as.character(
          Final_Data_nnmlp$FORECASTED_SALES)))-constant_value)
        
      }
      
      row.names(Final_Data_nnmlp) <- NULL
      
      list.sales_forecast_nnmlp[[i]] <- Final_Data_nnmlp
      
      #################################################################################################
      ############### Validation of Models ############################
      ##################################################################################################
      
      
      validation_qry <- paste0("SELECT 
                               a.DIMENSION1 as DIMENSION1,
                               a.DIMENSION2 as DIMENSION2,
                               a.DIMENSION3 as DIMENSION3,
                               a.DIMENSION4 as DIMENSION4,
                               a.DIMENSION5 as DIMENSION5,
                               cast(a.YEAR as integer) as YEAR,
                               cast(a.MONTH as integer) as MONTH",
                               if(exists("x_current_data")){",cast(k.ACTUAL_SALES as decimal(38,6)) as ACTUAL_SALES"} else{""},
                               if(exists("Final_Data_sma")){",cast(b.FORECASTED_SALES as decimal(38,6)) as SMA"} else{""},
                               if(exists("Final_Data_ets")){",cast(c.FORECASTED_SALES as decimal(38,6)) as ETS"} else{""},
                               if(exists("Final_Data_holtwinters")){",cast(d.FORECASTED_SALES as decimal(38,6)) as HOLT_WINTERS"} else{""},
                               if(exists("Final_Data_arima")){",cast(a.FORECASTED_SALES as decimal(38,6)) as ARIMA"} else{""},
                               if(exists("Final_Data_nnetar")){",cast(g.FORECASTED_SALES as decimal(38,6)) as NN_ETAR"} else{""},
                               if(exists("Final_Data_nnmlp")){",cast(h.FORECASTED_SALES as decimal(38,6)) as NN_MLP"} else{""},
                               
                               " from Final_Data_arima a ",
                               
                               if(exists("Final_Data_sma")){" inner join Final_Data_sma b on 
                                 a.DIMENSION1=b.DIMENSION1 and a.DIMENSION2=b.DIMENSION2 and 
                                 a.DIMENSION3=b.DIMENSION3 and a.DIMENSION4=b.DIMENSION4 and 
                                 a.DIMENSION5=b.DIMENSION5 and a.YEAR=b.YEAR and a.MONTH=b.MONTH"} else{""},
                               if(exists("Final_Data_ets")){" inner join Final_Data_ets c on 
                                 a.DIMENSION1=c.DIMENSION1 and a.DIMENSION2=c.DIMENSION2 and 
                                 a.DIMENSION3=c.DIMENSION3 and a.DIMENSION4=c.DIMENSION4 and 
                                 a.DIMENSION5=c.DIMENSION5 and a.YEAR=c.YEAR and a.MONTH=c.MONTH"} else{""},
                               if(exists("Final_Data_holtwinters")){" inner join Final_Data_holtwinters d on
                                 a.DIMENSION1=d.DIMENSION1 and a.DIMENSION2=d.DIMENSION2 and 
                                 a.DIMENSION3=d.DIMENSION3 and a.DIMENSION4=d.DIMENSION4 and 
                                 a.DIMENSION5=d.DIMENSION5 and a.YEAR=d.YEAR and a.MONTH=d.MONTH"} else{""},
                               if(exists("Final_Data_nnetar")){" inner join Final_Data_nnetar g on
                                 a.DIMENSION1=g.DIMENSION1 and a.DIMENSION2=g.DIMENSION2 and 
                                 a.DIMENSION3=g.DIMENSION3 and a.DIMENSION4=g.DIMENSION4 and 
                                 a.DIMENSION5=g.DIMENSION5 and a.YEAR=g.YEAR and a.MONTH=g.MONTH"} else{""},
                               if(exists("Final_Data_nnmlp")){" inner join Final_Data_nnmlp h on
                                 a.DIMENSION1=h.DIMENSION1 and a.DIMENSION2=h.DIMENSION2 and 
                                 a.DIMENSION3=h.DIMENSION3 and a.DIMENSION4=h.DIMENSION4 and 
                                 a.DIMENSION5=h.DIMENSION5 and a.YEAR=h.YEAR and a.MONTH=h.MONTH"} else{""},
                               if(exists("x_current_data")){" inner join x_current_data k on
                                 a.DIMENSION1=k.DIMENSION1 and a.DIMENSION2=k.DIMENSION2 and 
                                 a.DIMENSION3=k.DIMENSION3 and a.DIMENSION4=k.DIMENSION4 and 
                                 a.DIMENSION5=k.DIMENSION5 and a.YEAR=k.YEAR and a.MONTH=k.MONTH"} else{""},
                               " where a.YEAR==",current_year,
                               " and k.ACTUAL_SALES!=0 and k.MONTH<",
                               current_month,
                               sep="")
      
      
      validation_data <- sqldf(validation_qry)
      
      #########################################################################################################
      ################# Mean Absolute Percentage Error
      ############################################################################################
      
      SMA_Error <- mape(validation_data$ACTUAL_SALES,validation_data$SMA)*100
      
      ETS_Error <- mape(validation_data$ACTUAL_SALES,validation_data$ETS)*100
      
      Holtwinters_Error <- mape(validation_data$ACTUAL_SALES,validation_data$HOLT_WINTERS)*100
      
      ARIMA_Error <- mape(validation_data$ACTUAL_SALES,validation_data$ARIMA)*100
      
      NNMLP_Error <- mape(validation_data$ACTUAL_SALES,validation_data$NN_MLP)*100
      
      error_table <- as.data.frame(rbind(SMA_Error,ETS_Error,Holtwinters_Error,ARIMA_Error,NNMLP_Error))
      
      SF_Model <- rownames(error_table)
      
      row.names(error_table) <- NULL
      
      error_table <- cbind(as.character(SF_Model),error_table)
      
      colnames(error_table) <- c("Model","Error")
      
      
      min_error <- as.character(filter(error_table,Error==min(Error))$Model)
      
      Recommended_Model_Error <- as.numeric(as.character(filter(error_table,Error==min(Error))$Error))
      
      if(min_error=="SMA_Error") {
        Recommended_Model <- "SMA"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_sma,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else if(min_error=="ETS_Error") {
        Recommended_Model <- "ETS"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_ets,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else if(min_error=="Holtwinters_Error") {
        Recommended_Model <- "HOLTWINTERS"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_holtwinters,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else if(min_error=="ARIMA_Error") {
        Recommended_Model <- "ARIMA"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_arima,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else if(min_error=="NNETAR_Error") {
        Recommended_Model <- "NN_ETAR"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_nnetar,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else if(min_error=="NNMLP_Error") {
        Recommended_Model <- "NN_MLP"
        validation_data$RECOMMENDED_SALES_FORECAST <- filter(Final_Data_nnmlp,MONTH %in% validation_data$MONTH)$FORECASTED_SALES
      } else {
        print("Model Recommendation Process Failed")
      }
      
      
      sales_forecast_models_performance <- cbind(x_dimension1,x_dimension2,x_dimension3,
                                                 x_dimension4,x_dimension5,
                                                 SMA_Error,ETS_Error,Holtwinters_Error,ARIMA_Error,
                                                 NNMLP_Error,Recommended_Model,Recommended_Model_Error)
      
      colnames(sales_forecast_models_performance) <- c("DIMENSION1","DIMENSION2","DIMENSION3","DIMENSION4","DIMENSION5",
                                                       "SMA","ETS","HOLT_WINTERS","ARIMA",
                                                       "NN_MLP",
                                                       "RECOMMENDED_MODEL","RECOMMENDED_MODEL_ERROR")
      
      row.names(sales_forecast_models_performance) <- NULL
      
      list.sales_forecast_models_mape[[i]] <- as.data.frame(sales_forecast_models_performance)
      
      list.sales_forecast_validation[[i]] <- validation_data
      
                               })
    
    
    ######## Binding the list objects into a data frame and removing duplicates if any
    
    sales_forecast_validation <- do.call(rbind, list.sales_forecast_validation)
    
    sales_forecast_validation <- unique(sales_forecast_validation)
    
    sales_forecast_models_performance <- do.call(rbind,list.sales_forecast_models_mape)
    
    sales_forecast_models_performance <- unique(sales_forecast_models_performance)
    
    #######################################################################################
    #################### Loading data into Sales Forecast Validation #######################
    ########################################################################################
    
    if(exists("sales_forecast_validation") & nrow(sales_forecast_validation)>0){
      print("Loading the Sales Forecast Methods Comparison Results into DB")
      #dbSendQuery(mysql_db_connection,"truncate table AI_Sales_Forecast_Validation")
      
      validation_RUN_ID <- dbGetQuery(mysql_db_connection,"select max(RUN_ID) from AI_Sales_Forecast_Validation")
      
      new_validation_RUN_ID <- if(is.na(validation_RUN_ID)){1}else{validation_RUN_ID+1}
      
      for(i in 1:nrow(sales_forecast_validation)){
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_Validation",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,
                                               YEAR,MONTH,ACTUAL_SALES,SMA,ETS,HOLT_WINTERS,
                                               NN_MLP,ARIMA,RECOMMENDED_SALES_FORECAST) ",
                                               "values(",
                                               new_validation_RUN_ID,",",
                                               "'",sales_forecast_validation$DIMENSION1[i],"'",",",
                                               "'",sales_forecast_validation$DIMENSION2[i],"'",",",
                                               "'",sales_forecast_validation$DIMENSION3[i],"'",",",
                                               "'",sales_forecast_validation$DIMENSION4[i],"'",",",
                                               "'",sales_forecast_validation$DIMENSION5[i],"'",",",
                                               sales_forecast_validation$YEAR[i],",",
                                               sales_forecast_validation$MONTH[i],",",
                                               sales_forecast_validation$ACTUAL_SALES[i],",",
                                               sales_forecast_validation$SMA[i],",",
                                               sales_forecast_validation$ETS[i],",",
                                               sales_forecast_validation$HOLT_WINTERS[i],",",
                                               sales_forecast_validation$NN_MLP[i],",",
                                               sales_forecast_validation$ARIMA[i],",",
                                               sales_forecast_validation$RECOMMENDED_SALES_FORECAST[i],
                                               ")",sep=""))}
      print("Data Loading into Sales Forecast Validation Results Table is completed Successfully")
    } else {
      print("Sales Forecast Validation Results doesn't contain any Records")
    }
    
    
    #######################################################################################
    #################### Loading data into Forecast Models Performance  #######################
    ########################################################################################
    
    if(exists("sales_forecast_models_performance") & nrow(sales_forecast_models_performance)>0){
      print("Loading the Sales Forecast Models Performance Results into DB")
      #dbSendQuery(mysql_db_connection,"truncate table AI_Sales_Forecast_Models_Performance")
      
      mape_RUN_ID <- dbGetQuery(mysql_db_connection,"select max(RUN_ID) from AI_Sales_Forecast_Models_Performance")
      
      new_mape_RUN_ID <- if(is.na(mape_RUN_ID)){1}else{mape_RUN_ID+1}
      
      for(i in 1:nrow(sales_forecast_models_performance)){
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_Models_Performance",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,
                                               SMA,ETS,HOLT_WINTERS,
                                               ARIMA,NN_MLP,RECOMMENDED_MODEL,RECOMMENDED_MODEL_ERROR) ",
                                             "values(",
                                             new_mape_RUN_ID,",",
                                             "'",sales_forecast_models_performance$DIMENSION1[i],"'",",",
                                             "'",sales_forecast_models_performance$DIMENSION2[i],"'",",",
                                             "'",sales_forecast_models_performance$DIMENSION3[i],"'",",",
                                             "'",sales_forecast_models_performance$DIMENSION4[i],"'",",",
                                             "'",sales_forecast_models_performance$DIMENSION5[i],"'",",",
                                             sales_forecast_models_performance$SMA[i],",",
                                             sales_forecast_models_performance$ETS[i],",",
                                             sales_forecast_models_performance$HOLT_WINTERS[i],",",
                                             sales_forecast_models_performance$ARIMA[i],",",
                                             sales_forecast_models_performance$NN_MLP[i],",",
                                             "'",sales_forecast_models_performance$RECOMMENDED_MODEL[i],"',",
                                             sales_forecast_models_performance$RECOMMENDED_MODEL_ERROR[i],
                                             ")",sep=""))}
    print("Data Loading into Sales Forecast Validation Results Table is completed Successfully")
  } else {
    print("Sales Forecast Validation Results doesn't contain any Records")
  }
  
  
  #######################################################################################
  ############## Conditional Execution End Statements
  #######################################################################################
  
} else {
  
  print("Source Query Result set doesn't have any Records")
  
  print("Please Check the Staging SQL Query in the Source Definition Table")
  
}
  
  ##################################################################################################
  ############  Closing the Active Connections and clearing the workspace if needed
  #######################################################################################
  end_time <- Sys.time()
  
  execution_duration <- round(as.numeric(difftime(end_time, start_time,units="mins")),2)
  
  cat("The Execution Time(in Minutes) for the Model is:", execution_duration)
  
  ##################################################################################
  #################### Updating the AI Job Execution Summary 
  ##################################################################################
  
  dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                               SET JOB_END_DATETIME=",
                                                 "'",end_time,"'",
                                                 " , JOB_DURATION=",execution_duration,
                                                 " , JOB_RUN_STATUS=",
                                                 "'","Completed","'",
                                                 " , MODIFIED_DATETIME=",
                                                 "'",end_time,"'",
                                                 " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
  
  print("Disconnecting the open MYSQL Connections")
  dbDisconnect(mysql_db_connection)
  dbDisconnect(mysql_staging_db_connection) 
  dbDisconnect(mysql_app_db_connection)
  
  ####### Turning off the Log Sinking
  print("Closing the Log Sink Connection to the File")
  sink()
  
  #######################################################################################
  ##################################### End of the Code 
  ######################################################################################

  