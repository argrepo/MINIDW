#######################################################################################
############## Clearing the Plots and existing Objects
#######################################################################################
options(repos=structure(c(CRAN="https://cran.rstudio.com/")))

cores <- parallel::detectCores()

options(Ncpus = cores)

pdf(NULL)

rm(list=ls())


##########################################################################
#################################################################
##################### Input Parameters
#################################################################
############## DB Connectivity Parameters #########

args <- commandArgs(TRUE)

parameter_file_name <- args[1]


#param_input <- read.csv("param.csv",header=TRUE,stringsAsFactors = FALSE)

##### Reading the Parameter File
param_input <- read.csv(parameter_file_name,header=TRUE,stringsAsFactors = FALSE)

print("Preview of the Parameter File")
print(param_input)

client <- as.character(param_input$VALUE[param_input$PARAM=="client"])
app_db_host <- as.character(param_input$VALUE[param_input$PARAM=="app_db_host"])
app_db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="app_db_port"]))
app_db_name <- as.character(param_input$VALUE[param_input$PARAM=="app_db_name"])
app_db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="app_db_user_name"])
app_db_password <- as.character(param_input$VALUE[param_input$PARAM=="app_db_password"])
staging_db_host <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_host"])
staging_db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="staging_db_port"]))
staging_db_name <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_name"])
staging_db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_user_name"])
staging_db_password <- as.character(param_input$VALUE[param_input$PARAM=="staging_db_password"])
db_host <- as.character(param_input$VALUE[param_input$PARAM=="db_host"])
db_port <- as.integer(as.character(param_input$VALUE[param_input$PARAM=="db_port"]))
db_name <- as.character(param_input$VALUE[param_input$PARAM=="db_name"])
db_user_name <- as.character(param_input$VALUE[param_input$PARAM=="db_user_name"])
db_password <- as.character(param_input$VALUE[param_input$PARAM=="db_password"])
log_file_path <- as.character(param_input$VALUE[param_input$PARAM=="log_file_path"])
user_defined_functions_path <- as.character(param_input$VALUE[param_input$PARAM=="user_defined_functions_path"])
#user_defined_functions_path <- "/usr/_MINIDW/AIJOBS/AI_COMMON_JOBS/"


################## Model Specific Parameters ###########################

Business_Problem <- as.character(param_input$VALUE[param_input$PARAM=="Business Problem"])
Model_Name <- as.character(param_input$VALUE[param_input$PARAM=="Model Name"])
model_start_year <- 2015
model_start_month <- 1
differencing_order <- as.integer(param_input$VALUE[param_input$PARAM=="differencing_order"])
desired_forecast_period <- as.integer(param_input$VALUE[param_input$PARAM=="desired_forecast_period"])
data_points_criteria <- as.integer(param_input$VALUE[param_input$PARAM=="data_points_criteria"])

#model_end_year <- 2017
#model_end_month <- 12
current_year <- as.integer(param_input$VALUE[param_input$PARAM=="current_year"])
#current_year <- year(Sys.time())
#current_month <- month(Sys.time())
current_month <- as.integer(param_input$VALUE[param_input$PARAM=="current_month"])

###################################################################################
######################## Creating a Log File with the entire console execution
#############################################################################################

timestamp <- gsub(pattern=" ","",gsub(pattern = "[[:punct:]]","",as.character(Sys.time())))

log_file_name <- paste(client,"_",gsub(pattern = " ","_",Business_Problem),'_',gsub(pattern = " ","_",Model_Name),"_",timestamp,".log",sep="")

#### Sinking the console output to the Log File
sink(paste(log_file_path,"/",log_file_name,sep=""))

print(paste0("Log File Name: ",log_file_name,sep=""))

#### Capturing the start time of the code execution

start_time <- Sys.time()


####################################################################################
###################### Installing the required Packages and loading the libraries
#################################################################################

if(!require("nnfor")) install.packages("nnfor"); library("nnfor")
if(!require("DMwR")) install.packages("DMwR"); library("DMwR")
if(!require("plyr")) install.packages("plyr"); library("plyr")
if(!require("DBI")) install.packages("DBI"); library("DBI")
if(!require("RMySQL")) install.packages("RMySQL"); library("RMySQL")
if(!require("dplyr")) install.packages("dplyr"); library("dplyr")
if(!require("forecast")) install.packages("forecast"); library("forecast")
if(!require("sqldf")) install.packages("sqldf"); library("sqldf")
if(!require("data.table")) install.packages("data.table"); library("data.table")
if(!require("forecast")) install.packages("forecast"); library("forecast")
if(!require("readr")) install.packages("readr"); library("readr")
if(!require("Metrics")) install.packages("Metrics"); library("Metrics")
if(!require("smooth")) install.packages("smooth"); library("smooth")
if(!require("mice")) install.packages("mice"); library("mice")
if(!require("stringr")) install.packages("stringr", type="source"); library("stringr")
#if(!require("foreach")) install.packages("stringr", type="source"); library("foreach")
#if(!require("doParallel")) install.packages("doParallel", type="source"); library("doParallel")

###################### Setting the default options #################

###### setting default driver of sqldf library to SQLite
options(sqldf.driver = "SQLite")

###### Turning off the scientific Notation of Numbers
options(scipen = 999)

##################################################################################
############# Load the user defined functions ##################
##################################################################################


source(paste0(user_defined_functions_path,"connect_mysql_db.R",sep=""))
source(paste0(user_defined_functions_path,"get_AI_Model_Metadata.R",sep=""))
source(paste0(user_defined_functions_path,"staging_data_load.R",sep=""))
source(paste0(user_defined_functions_path,"data_quality_report.R",sep=""))
source(paste0(user_defined_functions_path,"missing_data_pattern_report.R",sep=""))
source(paste0(user_defined_functions_path,"numerical_data_summary_report.R",sep=""))
source(paste0(user_defined_functions_path,"string_data_summary_report.R",sep=""))
source(paste0(user_defined_functions_path,"basic_data_summary_report.R",sep=""))
source(paste0(user_defined_functions_path,"random_forest_imputation.R",sep=""))
source(paste0(user_defined_functions_path,"data_outliers_impute.R",sep=""))

############################################################################
############### Connecting to the managaeDB Database
#############################################################################

mysql_db_connection <- connect_mysql_db(db_host,db_port,db_name,db_user_name,db_password)
mysql_staging_db_connection <- connect_mysql_db(staging_db_host,staging_db_port,staging_db_name,
                                                staging_db_user_name,staging_db_password)
mysql_app_db_connection <- connect_mysql_db(app_db_host,app_db_port,app_db_name,app_db_user_name,app_db_password)

##################################################################################
#################### Updating the AI Job Execution Summary 
##################################################################################

AI_Job_RUN_ID <- dbGetQuery(mysql_staging_db_connection,"select max(RUN_ID) from AI_Jobs_Execution_Summary")

new_AI_Job_RUN_ID <- if(is.na(AI_Job_RUN_ID)){1}else{AI_Job_RUN_ID+1}

dbSendQuery(mysql_staging_db_connection,paste0("insert into AI_Jobs_Execution_Summary(
                                               RUN_ID,BUSINESS_PROBLEM,AI_MODEL,JOB_START_DATETIME,JOB_RUN_STATUS,JOB_LOG_FILENAME)
                                               VALUES(",
                                               new_AI_Job_RUN_ID,",",
                                               "'",Business_Problem,"',",
                                               "'",Model_Name,"',",
                                               "'",start_time,"'",",",
                                               "'","Started","'",",",
                                               "'",log_file_name,"')",
                                               sep=""))

############################################################################
############### Getting the AI Metadata
#############################################################################

AI_Metadata_Details <- get_AI_Model_Metadata(mysql_app_db_connection,Business_Problem,Model_Name)

############################################################################
############### Loading Source Data into Staging Table
#############################################################################

staging_sql <- as.character(AI_Metadata_Details$in_staging_sql_query)

staging_table_name <- as.character(AI_Metadata_Details$STAGING_TABLE)

source_records <- staging_data_load(mysql_staging_db_connection,mysql_db_connection,staging_sql,staging_table_name)

##################################################################################
#################### Updating the AI Job Execution Summary 
##################################################################################

dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                               SET SOURCE_RECORD_COUNT=",
                                               source_records,
                                               " , JOB_RUN_STATUS=",
                                               "'","Source Data Reading Completed","'",
                                               " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))

############################################################################
########### Conditional Execution of AI Model
############################################################################

if(exists("source_records") & source_records>0){
  
  print(paste0("Source Query Result set contains: ",source_records,sep=""))
  
  ############################################################################
  ############### Displaying the Source Data Summary Report
  #############################################################################
  
  data_quality_report(mysql_staging_db_connection,staging_table_name)
  
  ############################################################################
  ############### Applying Statistical Transformations
  #############################################################################
  
  staging_data <- dbGetQuery(mysql_staging_db_connection,paste0("select * from ",staging_table_name,sep=""))
  
  staging_records <- nrow(staging_data)
  
  ##################################################################################
  #################### Updating the AI Job Execution Summary 
  ##################################################################################
  
  dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                                 SET STAGING_RECORD_COUNT=",
                                                 staging_records,
                                                 " , JOB_RUN_STATUS=",
                                                 "'","Staging Load Completed","'",
                                                 " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
  
  transformed_data <- suppressWarnings(random_forest_imputation(staging_data,4,1234))
  
  ail_data <- transformed_data
  
  ail_table_name <- as.character(AI_Metadata_Details$AIL_TABLE)
  
  ######################### Loading the AIL Table ######################################
  #### Checking the count of records for transformed_data and then proceeding
  #### with loading the transformed_data into AIL Table
  
  if(exists("ail_data") & nrow(ail_data)>0){
    
    #### Truncating the AIL Table
    #### Right now, insert and update option of data loading is not implemented
    
    dbSendQuery(mysql_db_connection,paste0("truncate table ",ail_table_name,sep=""))
    
    #################### Looping through the entire data set to create the insert statements
    
    for(i in 1:nrow(ail_data)){
      
      dbSendQuery(mysql_db_connection,paste0("insert into ",ail_table_name, "(
                                             DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                                             YEAR,MONTH,ACTUAL_SALES) ",
                                             "values(",
                                             "\"",ail_data$DIMENSION1[i],"\"",",",
                                             "\"",ail_data$DIMENSION2[i],"\"",",",
                                             "\"",ail_data$DIMENSION3[i],"\"",",",
                                             "\"",ail_data$DIMENSION4[i],"\"",",",
                                             "\"",ail_data$DIMENSION5[i],"\"",",",
                                             ail_data$YEAR[i],",",ail_data$MONTH[i],",",
                                             ail_data$ACTUAL_SALES[i],")",sep="")) } 
    
    ########################### End of the Looping to insert the records into AIL Table
    
    print("Transformed Data Successfully Loaded into AIL Table")
    
    ##################### Dimensional Analysis and Loading it into AI_DP_Analysis Table
    
    ##########  Analyzing the combination of dimensions for data criteria 
    ###################################################
    
    #### Function to get unique records in the dimensions
    
    unique_rows <- function(input){
      if(sum(str_length(input))==0 &
         length(is.na(input))==length(input)) {
        unique_rows <- 0
      } else {
        unique_rows <- length(unique(input))
      }
    }
    
    ############################### End of the Function 
    
    Dimension_Analysis <- as.data.frame(apply(transformed_data[,1:5],2,unique_rows))
    column <- row.names(Dimension_Analysis)
    row.names(Dimension_Analysis) <- NULL
    Dimension_Analysis <- cbind(column,Dimension_Analysis)
    colnames(Dimension_Analysis) <- c("DIMENSION","UNIQUE_VALUES")
    
    
    print("Analyzing the Combination of Dimensions")
    print(Dimension_Analysis)
    valid_dimensions <- filter(Dimension_Analysis,UNIQUE_VALUES>0)
    print(paste("Dimensions having one or more unique values are: ", 
                paste(valid_dimensions$DIMENSION,collapse = ","),sep=""))
    
    
    #####################################################################################
    
    Dim_Data_Analysis <- sqldf("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                               max(YEAR) as MAX_YEAR, 
                               min(YEAR) as MIN_YEAR, count(*) as TOTAL_DATA_POINTS
                               from transformed_data 
                               group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5")
    
    Dim_Data_Analysis_historical <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                count(*) as HISTORICAL_DATA_POINTS
                                                from transformed_data
                                                where YEAR!=",current_year," 
                                                group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    Dim_Data_Analysis_historical_Sales <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                      sum(ACTUAL_SALES) as HISTORICAL_SALES
                                                      from transformed_data
                                                      where YEAR!=",current_year," 
                                                      group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    
    Dim_Data_Analysis_Current_Year <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                  count(*) as DATA_POINTS_CURRENT_YEAR
                                                  from transformed_data
                                                  where YEAR=",current_year," 
                                                  group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",sep=""))
    
    
    Dim_Data_Analysis_last2_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_2_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_last3_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_3_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,",",current_year-3,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_last4_years <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                                 count(*) as DATA_POINTS_PAST_4_YEARS
                                                 from transformed_data
                                                 where YEAR in (",current_year-1,",",current_year-2,",",current_year-3,
                                                 ",",current_year-4,")
                                                 group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5"))
    
    Dim_Data_Analysis_CYMM <- sqldf(paste("select DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5,
                                          max(MONTH) as CURRENT_YEAR_MAX_MONTH
                                          from transformed_data
                                          where YEAR==",current_year," 
                                          group by DIMENSION1, DIMENSION2, DIMENSION3,DIMENSION4,DIMENSION5",
                                          sep=""))
    
    
    Dim_Data_Analysis_Combined <- sqldf("select x.*, y.HISTORICAL_DATA_POINTS,
                                        e.HISTORICAL_SALES,
                                        a.DATA_POINTS_PAST_2_YEARS,
                                        b.DATA_POINTS_PAST_3_YEARS,
                                        c.DATA_POINTS_PAST_4_YEARS,
                                        z.DATA_POINTS_CURRENT_YEAR,
                                        d.CURRENT_YEAR_MAX_MONTH
                                        from Dim_Data_Analysis x
                                        left outer join Dim_Data_Analysis_historical y
                                        on (x.DIMENSION1=y.DIMENSION1 and
                                        x.DIMENSION2=y.DIMENSION2 and
                                        x.DIMENSION3=y.DIMENSION3 and
                                        x.DIMENSION4=y.DIMENSION4 and 
                                        x.DIMENSION5=y.DIMENSION5)
                                        left outer join Dim_Data_Analysis_historical_Sales e
                                        on (x.DIMENSION1=e.DIMENSION1 and
                                        x.DIMENSION2=e.DIMENSION2 and
                                        x.DIMENSION3=e.DIMENSION3 and
                                        x.DIMENSION4=e.DIMENSION4 and 
                                        x.DIMENSION5=e.DIMENSION5)
                                        left outer join Dim_Data_Analysis_Current_Year z
                                        on (x.DIMENSION1=z.DIMENSION1 and
                                        x.DIMENSION2=z.DIMENSION2 and
                                        x.DIMENSION3=z.DIMENSION3 and
                                        x.DIMENSION4=z.DIMENSION4 and 
                                        x.DIMENSION5=z.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last2_years a
                                        on (x.DIMENSION1=a.DIMENSION1 and
                                        x.DIMENSION2=a.DIMENSION2 and
                                        x.DIMENSION3=a.DIMENSION3 and
                                        x.DIMENSION4=a.DIMENSION4 and 
                                        x.DIMENSION5=a.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last3_years b
                                        on (x.DIMENSION1=b.DIMENSION1 and
                                        x.DIMENSION2=b.DIMENSION2 and
                                        x.DIMENSION3=b.DIMENSION3 and
                                        x.DIMENSION4=b.DIMENSION4 and 
                                        x.DIMENSION5=b.DIMENSION5)
                                        left outer join Dim_Data_Analysis_last4_years c
                                        on (x.DIMENSION1=c.DIMENSION1 and
                                        x.DIMENSION2=c.DIMENSION2 and
                                        x.DIMENSION3=c.DIMENSION3 and
                                        x.DIMENSION4=c.DIMENSION4 and 
                                        x.DIMENSION5=c.DIMENSION5)
                                        left outer join  Dim_Data_Analysis_CYMM d
                                        on (x.DIMENSION1=d.DIMENSION1 and
                                        x.DIMENSION2=d.DIMENSION2 and
                                        x.DIMENSION3=d.DIMENSION3 and
                                        x.DIMENSION4=d.DIMENSION4 and 
                                        x.DIMENSION5=d.DIMENSION5)"
    )
    
    ### Removing the temp objects of dim analysis
    rm(Dim_Data_Analysis,Dim_Data_Analysis_Current_Year,Dim_Data_Analysis_historical,
       Dim_Data_Analysis_historical_Sales,
       Dim_Data_Analysis_last2_years,Dim_Data_Analysis_last3_years,
       Dim_Data_Analysis_last4_years, Dim_Data_Analysis_CYMM)
    
    ### Replacing NAs with Zero
    Dim_Data_Analysis_Combined[is.na(Dim_Data_Analysis_Combined)] <- 0 
    
    ## Checking the valid combinations of the Dimensions
    Valid_Data <- subset(Dim_Data_Analysis_Combined,
                         Dim_Data_Analysis_Combined$TOTAL_DATA_POINTS>=data_points_criteria & 
                           Dim_Data_Analysis_Combined$MAX_YEAR==current_year &
                           Dim_Data_Analysis_Combined$DATA_POINTS_PAST_2_YEARS==24 &
                           Dim_Data_Analysis_Combined$HISTORICAL_SALES>0)
    
    Invalid_Data <- subset(Dim_Data_Analysis_Combined,
                           Dim_Data_Analysis_Combined$TOTAL_DATA_POINTS<data_points_criteria | 
                             Dim_Data_Analysis_Combined$MAX_YEAR!=current_year |
                             Dim_Data_Analysis_Combined$DATA_POINTS_PAST_2_YEARS<24 |
                             Dim_Data_Analysis_Combined$HISTORICAL_SALES<=0)
    
    ### Printing the count of Valid and Invalid combinations of Dimensions
    print(paste0("Valid Combinations of Dimensions for Forecasting: ",nrow(Valid_Data),sep=""))
    
    print(paste0("Invalid Combinations of Dimensions for Forecasting: ",nrow(Dim_Data_Analysis_Combined)-nrow(Valid_Data),sep=""))
    print("Check the Data Analysis Table for more information")
    
    #######################################################################################
    ############# Writing the Valid and Invalid Dimension - Data Criteria Check
    ######################################################################################
    
    if(exists("Valid_Data") & nrow(Valid_Data)>0){
      
      print("Loading the Sales Forecast Valid Data Points Analysis into DB Table")
      
      #### Looping through the DP Analysis and creating insert statements
      
      #### Getting the RUN_ID from the table
      
      DP_Analysis_Valid_RUN_ID <- dbGetQuery(mysql_db_connection,
                                             "select max(RUN_ID) from AI_Sales_Forecast_DP_Valid")
      
      new_DP_Analysis_Valid_RUN_ID <- if(is.na(DP_Analysis_Valid_RUN_ID)){1}else{DP_Analysis_Valid_RUN_ID+1}
      
      
      for(i in 1:nrow(Valid_Data)){
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_DP_Valid",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,MAX_YEAR,MIN_YEAR,TOTAL_DATA_POINTS,
                                               HISTORICAL_DATA_POINTS,HISTORICAL_SALES,
                                               DATA_POINTS_LAST_2_YEARS,
                                               DATA_POINTS_LAST_3_YEARS,DATA_POINTS_LAST_4_YEARS,
                                               DATA_POINTS_CURRENT_YEAR,CURRENT_YEAR_MAX_MONTH) ",
                                               "values(",new_DP_Analysis_Valid_RUN_ID,",",
                                               "'",Valid_Data$DIMENSION1[i],"'",",",
                                               "'",Valid_Data$DIMENSION2[i],"'",",",
                                               "'",Valid_Data$DIMENSION3[i],"'",",",
                                               "'",Valid_Data$DIMENSION4[i],"'",",",
                                               "'",Valid_Data$DIMENSION5[i],"'",",",
                                               Valid_Data$MAX_YEAR[i],",",
                                               Valid_Data$MIN_YEAR[i],",",
                                               Valid_Data$TOTAL_DATA_POINTS[i],",",
                                               Valid_Data$HISTORICAL_DATA_POINTS[i],",",
                                               Valid_Data$HISTORICAL_SALES[i],",",
                                               Valid_Data$DATA_POINTS_PAST_2_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_PAST_3_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_PAST_4_YEARS[i],",",
                                               Valid_Data$DATA_POINTS_CURRENT_YEAR[i],",",
                                               Valid_Data$CURRENT_YEAR_MAX_MONTH[i],
                                               ")",sep=""))}
      
      print("Data Loading into Valid Data Points Analysis Table is completed Successfully") 
      
    } else {
      
      print("Error Occured in Dimensional Data Analysis/No Valid Data Points")
      print("Please check the Transformed Data Object")
      
    }
    
    
    if(exists("Invalid_Data") & nrow(Invalid_Data)>0){
      
      print("Loading the Sales Forecast Invalid Data Points Analysis into DB Table")
      
      #### Looping through the DP Analysis and creating insert statements
      
      #### Getting the RUN_ID from the table
      
      DP_Analysis_Invalid_RUN_ID <- dbGetQuery(mysql_db_connection,
                                               "select max(RUN_ID) from AI_Sales_Forecast_DP_Invalid")
      
      new_DP_Analysis_Invalid_RUN_ID <- if(is.na(DP_Analysis_Invalid_RUN_ID)){1}else{DP_Analysis_Invalid_RUN_ID+1}
      
      
      for(i in 1:nrow(Invalid_Data)){
        dbSendQuery(mysql_db_connection,paste0("insert into AI_Sales_Forecast_DP_Invalid",
                                               "(RUN_ID,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                               DIMENSION5,MAX_YEAR,MIN_YEAR,TOTAL_DATA_POINTS,
                                               HISTORICAL_DATA_POINTS,HISTORICAL_SALES,
                                               DATA_POINTS_LAST_2_YEARS,
                                               DATA_POINTS_LAST_3_YEARS,DATA_POINTS_LAST_4_YEARS,
                                               DATA_POINTS_CURRENT_YEAR,CURRENT_YEAR_MAX_MONTH) ",
                                               "values(",new_DP_Analysis_Invalid_RUN_ID,",",
                                               "'",Invalid_Data$DIMENSION1[i],"'",",",
                                               "'",Invalid_Data$DIMENSION2[i],"'",",",
                                               "'",Invalid_Data$DIMENSION3[i],"'",",",
                                               "'",Invalid_Data$DIMENSION4[i],"'",",",
                                               "'",Invalid_Data$DIMENSION5[i],"'",",",
                                               Invalid_Data$MAX_YEAR[i],",",
                                               Invalid_Data$MIN_YEAR[i],",",
                                               Invalid_Data$TOTAL_DATA_POINTS[i],",",
                                               Invalid_Data$HISTORICAL_DATA_POINTS[i],",",
                                               Invalid_Data$HISTORICAL_SALES[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_2_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_3_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_PAST_4_YEARS[i],",",
                                               Invalid_Data$DATA_POINTS_CURRENT_YEAR[i],",",
                                               Invalid_Data$CURRENT_YEAR_MAX_MONTH[i],
                                               ")",sep=""))}
      
      ##### End of Data Loading Looping
      print("Data Loading into Invalid Data Points Analysis Table is completed Successfully") 
      
    } else {
      
      print("Error Occured in Dimensional Data Analysis/No Invalid Data Points")
      print("Please check the Transformed Data Object")
      
    }
    
    
    
  } else {
    
    print("Transformed Data Object not found")
    print("Error might have occured in transforming the staging Data")
    
  }
  
  ############################## End of Loading of AIL Table #################################
  ############################## End of Loading of AI DP Analysis Table ######################
  
  
  ##################################################################################
  #################### Updating the AI Job Execution Summary 
  ##################################################################################
  
  ail_record_count <- dbGetQuery(mysql_db_connection,"select count(1) from AIL_Sales_Forecast")
  
  dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                                 SET AIL_RECORD_COUNT=",
                                                 ail_record_count,
                                                 " , JOB_RUN_STATUS=",
                                                 "'","AIL Data Load Completed","'",
                                                 " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
  
  ###############################################################################################
  ############ Ignoring the current month Sales to train the Model ########################
  ####### Reason: To Provide Forecast to the current Month too ########################################
  
  transformed_data <- sqldf(paste("select * from transformed_data where YEAR<",current_year,
                                  " union
                                  select * from transformed_data where YEAR==",current_year,
                                  " and MONTH <",current_month,sep=""))
  
  ################### Getting the Best Recommended Model Sales from the Validation_Results
  
  best_performing_models <- dbGetQuery(mysql_db_connection,
                                       "select DIMENSION1, DIMENSION2, DIMENSION3, 
                                       DIMENSION4, DIMENSION5, RECOMMENDED_MODEL
                                       from AI_Sales_Forecast_Models_Performance
                                       where RUN_ID=(select max(RUN_ID) from AI_Sales_Forecast_Models_Performance)")
  
  ##################################################################################################
  ####################### Sales Forecast Models Validation for Dimensional Combinations ##############
  #################################################################################################
  
  ##### Assigning the list objects for various SF Models
  
  list.sales_forecast_arima <- list()
  
  list.sales_forecast_nnmlp <- list()
  
  list.sales_forecast_ets <- list()
  
  list.sales_forecast_sma <- list()
  
  list.sales_forecast_holtwinters <- list()
  
  list.sales_forecast_recommended <- list()
  
  ###### Looping through every combination of valid Data Combination 
  
  i <- 1
  
  for(i in 1:nrow(Valid_Data))
    
  {
    
    ###### Dynamically checking the availability of DP
    ##### finding out the start year for each combination
    
    if(Valid_Data$DATA_POINTS_PAST_4_YEARS[i]==48){
      valid_start_year <- current_year-4
    } else if (Valid_Data$DATA_POINTS_PAST_3_YEARS[i]==36) {
      valid_start_year <- current_year-3
    } else if (Valid_Data$DATA_POINTS_PAST_2_YEARS[i]==24){
      valid_start_year <- current_year-2
    } else {
      valid_start_year <- NULL
    }
    
    #### Start Year Check Completed
    
    x_dimension1 <- Valid_Data$DIMENSION1[i]
    x_dimension2 <- Valid_Data$DIMENSION2[i]
    x_dimension3 <- Valid_Data$DIMENSION3[i]
    x_dimension4 <- Valid_Data$DIMENSION4[i]
    x_dimension5 <- Valid_Data$DIMENSION5[i]
    x_current_year_max_month <- Valid_Data$CURRENT_YEAR_MAX_MONTH[i]
    
    
    x_data <- subset(transformed_data,(transformed_data$DIMENSION1==x_dimension1 &
                                         transformed_data$DIMENSION2==x_dimension2 &
                                         transformed_data$DIMENSION3==x_dimension3 &
                                         transformed_data$DIMENSION4==x_dimension4 &
                                         transformed_data$DIMENSION5==x_dimension5 &
                                         transformed_data$YEAR>=valid_start_year))
    
    #### Imputing any Zero Values with Median
    
    x_data$ACTUAL_SALES[x_data$ACTUAL_SALES==0] <- median(x_data$ACTUAL_SALES)
    
    ### Imputing the outliers with Median
    
    x_data$ACTUAL_SALES <- data_outliers_impute(x_data$ACTUAL_SALES,"median")
    
    #### Checking whether the data contains zero or Negative Values
    
    if(nrow(filter(x_data,ACTUAL_SALES==0 | ACTUAL_SALES<0))==0) {
      
      x_data$ACTUAL_SALES <- log1p(x_data$ACTUAL_SALES)
      
      flag_zero_negative <- 0
      
    } else {
      
      ### Finding the constant value to add to handle zero and Negative Values
      
      constant_value <- abs(min(x_data$ACTUAL_SALES))+0.0001
      
      #### Adding the constant Value to all the Sales Amount
      
      x_data$ACTUAL_SALES <- x_data$ACTUAL_SALES+constant_value
      
      #### Applying Log Transformation to the Sales Amount
      
      x_data$ACTUAL_SALES <- log1p(x_data$ACTUAL_SALES)
      
      flag_zero_negative <- 1
      
    }
    
    
    ### Creating the time series object
    
    data.ts <- ts(x_data$ACTUAL_SALES,start=c(valid_start_year,01),end=c(current_year,current_month-1),frequency = 12)
    
    ## Plotting the time series object
    
    #plot(data.ts)
    ## Fitting a straight Line
    #abline(reg=lm(data.ts~time(data.ts)))
    #Plotting the decomposition of Time series
    #(Seasonal, Trend and Irregular components)
    #plot(decompose(data.ts))
    #out_decompose <- decompose(data.ts)
    #Add_multiply_type <- out_decompose$type
    #print(paste("The type of model(Additive/Multiplicative):",Add_multiply_type ))
    
    ### Cycle across the years
    #cycle(data.ts)
    #aggregate the cycles and display a year on year trend
    #plot(aggregate(data.ts,FUN=mean))
    #Plotting the differences in the time series to make it stationary
    #diff(data.ts)
    #differenced_time_series <- diff(data.ts, differences = 2)
    #plot(differenced_time_series)
    
    #######################################################################
    ############################ Building the Arima Model
    ##########################################################################
    
    arima.model <- auto.arima(data.ts,stationary = FALSE, seasonal = FALSE)
    
    #summary(arima.model)
    #### Calculating the new forecast period to accomodate the validation and customer desired forecast period
    
    new_desired_forecast_period <- desired_forecast_period
    
    predicted_data <- forecast(arima.model,new_desired_forecast_period)
    
    ## Plotting the predicted Values
    #plot(predicted_data)
    
    #autoplot(predicted_data)
    arima_method <- predicted_data$method
    
    ### creating the Forecast Method Variable
    
    FORECAST_METHOD <- data.frame(rep('AUTO ARIMA',new_desired_forecast_period))
    colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    
    ### Creating the Dimensions variables
    
    DIMENSION1 <- rep(x_dimension1,new_desired_forecast_period)
    DIMENSION2 <- rep(x_dimension2,new_desired_forecast_period)
    DIMENSION3 <- rep(x_dimension3,new_desired_forecast_period)
    DIMENSION4 <- rep(x_dimension4,new_desired_forecast_period)
    DIMENSION5 <- rep(x_dimension5,new_desired_forecast_period)
    
    Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    
    ### Creating the Measures Variables
    
    PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data))
    YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
    MONTH <- substr(PREDICTED_PERIOD,1,3)
    
    x_predicted_data <- as.data.frame(predicted_data)
    
    FORECASTED_SALES <- as.numeric(x_predicted_data[,1])
    
    Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    
    ### Creatning the Final Data Frame
    
    Final_Data_arima <- cbind(Dimensions,Measures)
    
    ### Storing the Arima Method for every Combination
    #Final_Data_Arima_Method <- cbind(Dimensions[,-1],arima_method)
    
    ### Changing the MMM format to MM Format for Month
    
    Final_Data_arima <- sqldf("select FORECAST_METHOD,
                              DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                              YEAR,
                              case 
                              when MONTH='Jan' then 1
                              when MONTH='Feb' then 2
                              when MONTH='Mar' then 3
                              when MONTH='Apr' then 4
                              when MONTH='May' then 5
                              when MONTH='Jun' then 6
                              when MONTH='Jul' then 7
                              when MONTH='Aug' then 8
                              when MONTH='Sep' then 9
                              when MONTH='Oct' then 10
                              when MONTH='Nov' then 11
                              when MONTH='Dec' then 12
                              else MONTH end as MONTH,
                              cast(FORECASTED_SALES as decimal(38,16)) as FORECASTED_SALES
                              from Final_Data_arima")
    
    ### Back Transforming the output
    
    if(flag_zero_negative==0) {
      
      Final_Data_arima$FORECASTED_SALES <- expm1(as.numeric(as.character(
        Final_Data_arima$FORECASTED_SALES)))
    } else {
      
      Final_Data_arima$FORECASTED_SALES <- (expm1(as.numeric(as.character(
        Final_Data_arima$FORECASTED_SALES)))-constant_value)
      
    }
    
    row.names(Final_Data_arima) <- NULL
    
    list.sales_forecast_arima[[i]] <- Final_Data_arima
    
    #list.arima.method[[i]] <- arima_method
    
    #######################################################################################
    #########      Exponential Smoothing Method
    #######################################################################################
    
    ets_data.ts <- ets(data.ts, model="ZZZ", damped = NULL)
    
    #plot(ets_data.ts)
    #summary(ets_data.ts)
    
    predicted_data_ets <- forecast(ets_data.ts, new_desired_forecast_period)
    
    # Plotting the forecasted Data
    #plot(predicted_data_ets)
    #autoplot(predicted_data_ets)
    
    FORECAST_METHOD <- data.frame(rep('ETS',new_desired_forecast_period))
    
    colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    
    Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    
    PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_ets))
    YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
    MONTH <- substr(PREDICTED_PERIOD,1,3)
    
    x_predicted_data <- as.data.frame(predicted_data_ets)
    
    FORECASTED_SALES <- as.numeric(x_predicted_data[,1])
    
    Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    
    Final_Data_ets <- cbind(Dimensions,Measures)
    
    Final_Data_ets <- sqldf("select FORECAST_METHOD,
                            DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                            YEAR,
                            case 
                            when MONTH='Jan' then 1
                            when MONTH='Feb' then 2
                            when MONTH='Mar' then 3
                            when MONTH='Apr' then 4
                            when MONTH='May' then 5
                            when MONTH='Jun' then 6
                            when MONTH='Jul' then 7
                            when MONTH='Aug' then 8
                            when MONTH='Sep' then 9
                            when MONTH='Oct' then 10
                            when MONTH='Nov' then 11
                            when MONTH='Dec' then 12
                            else MONTH end as MONTH,FORECASTED_SALES
                            from Final_Data_ets")
    
    ### Back Transforming the output
    
    if(flag_zero_negative==0) {
      
      Final_Data_ets$FORECASTED_SALES <- expm1(as.numeric(as.character(
        Final_Data_ets$FORECASTED_SALES)))
    } else {
      
      Final_Data_ets$FORECASTED_SALES <- (expm1(as.numeric(as.character(
        Final_Data_ets$FORECASTED_SALES)))-constant_value)
      
    }
    
    row.names(Final_Data_ets) <- NULL
    
    list.sales_forecast_ets[[i]] <- Final_Data_ets
    
    ######################################################################################
    #######################################################################################
    #################### Simple Moving Average
    #######################################################################################
    
    sma_model <- sma(data.ts,h=new_desired_forecast_period)
    
    predicted_data_sma <- forecast(sma_model, new_desired_forecast_period)
    
    #plot(predicted_data_sma)
    
    FORECAST_METHOD <- data.frame(rep('SMA',new_desired_forecast_period))
    
    colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    
    Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    
    PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_sma))
    
    YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
    
    MONTH <- substr(PREDICTED_PERIOD,1,3)
    
    x_predicted_data <- as.data.frame(predicted_data_sma$mean)
    
    FORECASTED_SALES <- abs(as.numeric(x_predicted_data[,1]))
    
    Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    
    Final_Data_sma <- cbind(Dimensions,Measures)
    
    Final_Data_sma <- sqldf("select FORECAST_METHOD,
                            DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                            YEAR,
                            case 
                            when MONTH='Jan' then 1
                            when MONTH='Feb' then 2
                            when MONTH='Mar' then 3
                            when MONTH='Apr' then 4
                            when MONTH='May' then 5
                            when MONTH='Jun' then 6
                            when MONTH='Jul' then 7
                            when MONTH='Aug' then 8
                            when MONTH='Sep' then 9
                            when MONTH='Oct' then 10
                            when MONTH='Nov' then 11
                            when MONTH='Dec' then 12
                            else MONTH end as MONTH,FORECASTED_SALES
                            from Final_Data_sma")
    
    ### Back Transforming the output
    
    if(flag_zero_negative==0) {
      
      Final_Data_sma$FORECASTED_SALES <- expm1(as.numeric(as.character(
        Final_Data_sma$FORECASTED_SALES)))
    } else {
      
      Final_Data_sma$FORECASTED_SALES <- (expm1(as.numeric(as.character(
        Final_Data_sma$FORECASTED_SALES)))-constant_value)
      
    }
    
    
    row.names(Final_Data_sma) <- NULL
    
    list.sales_forecast_sma[[i]] <- Final_Data_sma
    
    
    # #######################################################################################
    # ############## Holts Winter Method with Seasonality
    # #######################################################################################
    # #beta=FALSE to facilitate the exponential smoothing
    # 
    # holt_winters_model <- HoltWinters(data.ts)
    # 
    # #summary(holt_winters_model)
    # 
    # predicted_data_holtwinters <- forecast(holt_winters_model,new_desired_forecast_period)
    # 
    # #plot(predicted_data_holtwinters)
    # 
    # FORECAST_METHOD <- data.frame(rep('HOLT WINTERS',new_desired_forecast_period))
    # 
    # colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    # 
    # Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    # 
    # PREDICTED_PERIOD <- row.names(as.data.frame(predicted_data_holtwinters))
    # 
    # YEAR <- substr(PREDICTED_PERIOD,(nchar(PREDICTED_PERIOD)+1)-4,nchar(PREDICTED_PERIOD))
    # 
    # MONTH <- substr(PREDICTED_PERIOD,1,3)
    # 
    # FORECASTED_SALES <- as.numeric(predicted_data_holtwinters$mean)
    # 
    # Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    # 
    # Final_Data_holtwinters <- cbind(Dimensions,Measures)
    # 
    # Final_Data_holtwinters <- sqldf("select FORECAST_METHOD,
    #                                 DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
    #                                 YEAR,
    #                                 case 
    #                                 when MONTH='Jan' then 1
    #                                 when MONTH='Feb' then 2
    #                                 when MONTH='Mar' then 3
    #                                 when MONTH='Apr' then 4
    #                                 when MONTH='May' then 5
    #                                 when MONTH='Jun' then 6
    #                                 when MONTH='Jul' then 7
    #                                 when MONTH='Aug' then 8
    #                                 when MONTH='Sep' then 9
    #                                 when MONTH='Oct' then 10
    #                                 when MONTH='Nov' then 11
    #                                 when MONTH='Dec' then 12
    #                                 else MONTH end as MONTH,FORECASTED_SALES
    #                                 from Final_Data_holtwinters")
    # 
    # ### Back Transforming the output
    # 
    # if(flag_zero_negative==0) {
    #   
    #   Final_Data_holtwinters$FORECASTED_SALES <- expm1(as.numeric(as.character(
    #     Final_Data_holtwinters$FORECASTED_SALES)))
    # } else {
    #   
    #   Final_Data_holtwinters$FORECASTED_SALES <- (expm1(as.numeric(as.character(
    #     Final_Data_holtwinters$FORECASTED_SALES)))-constant_value)
    #   
    # }
    # 
    # 
    # row.names(Final_Data_holtwinters) <- NULL
    # 
    # list.sales_forecast_holtwinters[[i]] <- Final_Data_holtwinters
    
    #######################################################################################
    ########################## Neural Networks - ETAR
    #######################################################################################
    
    ### estimation type is set to step -- stepwise regression with AIC
    ### input is given as actual time series object instead of differenced object
    ### since it will be handled in the model itself automatically
    
    # nnetar_model <- nnetar(data.ts,lambda = 0,p=11)
    # 
    # # Forecasting the Sales for n months
    # 
    # predicted_data <- forecast(nnetar_model,new_desired_forecast_period)
    # 
    # plot(predicted_data)
    # 
    # FORECAST_METHOD <- data.frame(rep('NN-ETAR',new_desired_forecast_period))
    # 
    # colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    # 
    # Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    # 
    # x_predicted_data <- as.data.frame(predicted_data$mean)
    # 
    # FORECASTED_SALES <- as.numeric(x_predicted_data$x)
    # 
    # Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    # 
    # Final_Data_nnetar <- cbind(Dimensions,Measures)
    # 
    # Final_Data_nnetar <- sqldf("select FORECAST_METHOD,
    #                            DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
    #                            YEAR,
    #                            case 
    #                            when MONTH='Jan' then 1
    #                            when MONTH='Feb' then 2
    #                            when MONTH='Mar' then 3
    #                            when MONTH='Apr' then 4
    #                            when MONTH='May' then 5
    #                            when MONTH='Jun' then 6
    #                            when MONTH='Jul' then 7
    #                            when MONTH='Aug' then 8
    #                            when MONTH='Sep' then 9
    #                            when MONTH='Oct' then 10
    #                            when MONTH='Nov' then 11
    #                            when MONTH='Dec' then 12
    #                            else MONTH end as MONTH,FORECASTED_SALES
    #                            from Final_Data_nnetar")
    # 
    # if(flag_zero_negative==0) {
    #   
    #   Final_Data_nnetar$FORECASTED_SALES <- expm1(as.numeric(as.character(
    #     Final_Data_nnetar$FORECASTED_SALES)))
    # } else {
    #   
    #   Final_Data_nnetar$FORECASTED_SALES <- (expm1(as.numeric(as.character(
    #     Final_Data_nnetar$FORECASTED_SALES)))-constant_value)
    #   
    # }
    # 
    # row.names(Final_Data_nnetar) <- NULL
    # 
    # list.sales_forecast_nnetar[[i]] <- Final_Data_nnetar
    
    #######################################################################################
    ##################### Neural Networks - MLP - Multi Layer Perceptron
    #######################################################################################
    
    nnmlp_model <- mlp(data.ts)
    
    predicted_data <- forecast(nnmlp_model,new_desired_forecast_period)
    
    #plot(predicted_data)
    
    FORECAST_METHOD <- data.frame(rep('NN-MLP',new_desired_forecast_period))
    
    colnames(FORECAST_METHOD) <- "FORECAST_METHOD"
    
    Dimensions <- cbind(FORECAST_METHOD,DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5)
    
    x_predicted_data <- as.data.frame(predicted_data$mean)
    
    FORECASTED_SALES <- as.numeric(x_predicted_data$x)
    
    Measures <- cbind(YEAR,MONTH,FORECASTED_SALES)
    
    Final_Data_nnmlp <- cbind(Dimensions,Measures)
    
    Final_Data_nnmlp <- sqldf("select FORECAST_METHOD,
                              DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,DIMENSION5,
                              YEAR,
                              case 
                              when MONTH='Jan' then 1
                              when MONTH='Feb' then 2
                              when MONTH='Mar' then 3
                              when MONTH='Apr' then 4
                              when MONTH='May' then 5
                              when MONTH='Jun' then 6
                              when MONTH='Jul' then 7
                              when MONTH='Aug' then 8
                              when MONTH='Sep' then 9
                              when MONTH='Oct' then 10
                              when MONTH='Nov' then 11
                              when MONTH='Dec' then 12
                              else MONTH end as MONTH,FORECASTED_SALES
                              from Final_Data_nnmlp")
    
    if(flag_zero_negative==0) {
      
      Final_Data_nnmlp$FORECASTED_SALES <- expm1(as.numeric(as.character(
        Final_Data_nnmlp$FORECASTED_SALES)))
    } else {
      
      Final_Data_nnmlp$FORECASTED_SALES <- (expm1(as.numeric(as.character(
        Final_Data_nnmlp$FORECASTED_SALES)))-constant_value)
      
    }
    
    row.names(Final_Data_nnmlp) <- NULL
    
    list.sales_forecast_nnmlp[[i]] <- Final_Data_nnmlp
    
    x_best_model <- filter(best_performing_models,DIMENSION1==x_dimension1 & DIMENSION2==x_dimension2 &
                             DIMENSION3==x_dimension3 & DIMENSION4==x_dimension4 & DIMENSION5==x_dimension5)
    
    
    if(x_best_model$RECOMMENDED_MODEL=="SMA") {
      Recommended_Model_Data <- Final_Data_sma
    } else if(x_best_model$RECOMMENDED_MODEL=="ARIMA") {
      Recommended_Model_Data <- Final_Data_arima
    } else if(x_best_model$RECOMMENDED_MODEL=="ETS") {
      Recommended_Model_Data <- Final_Data_ets
    } else if(x_best_model$RECOMMENDED_MODEL=="HOLTWINTERS") {
      Recommended_Model_Data <- Final_Data_ets
    } else if(x_best_model$RECOMMENDED_MODEL=="NN_MLP") {
      Recommended_Model_Data <- Final_Data_nnmlp
    } else {
      print("Model Recommendation Process Failed")
    }
    
    list.sales_forecast_recommended[[i]] <- Recommended_Model_Data
    
  }
  
  
  ######## Binding the list objects into a data frame
  
  sales_forecast_recommended <- do.call(rbind, list.sales_forecast_recommended)
  
  ######### Loading the recommended sales data into AOL Table
  
  aol_table_name <- as.character(AI_Metadata_Details$AOL_TABLE)
  
  if(exists("sales_forecast_recommended") & nrow(sales_forecast_recommended)>0){
    print("Loading the Recommended Sales Forecast Output into AOL Table")
    dbSendQuery(mysql_db_connection,paste0("truncate table ",aol_table_name,sep=""))
    for(i in 1:nrow(sales_forecast_recommended)){
      dbSendQuery(mysql_db_connection,paste0("insert into ", aol_table_name,
                                             "(
                                             DIMENSION1,DIMENSION2,DIMENSION3,DIMENSION4,
                                             DIMENSION5,
                                             YEAR,MONTH,FORECASTED_SALES) ",
                                             "values(",
                                             "'",sales_forecast_recommended$DIMENSION1[i],"'",",",
                                             "'",sales_forecast_recommended$DIMENSION2[i],"'",",",
                                             "'",sales_forecast_recommended$DIMENSION3[i],"'",",",
                                             "'",sales_forecast_recommended$DIMENSION4[i],"'",",",
                                             "'",sales_forecast_recommended$DIMENSION5[i],"'",",",
                                             sales_forecast_recommended$YEAR[i],",",
                                             sales_forecast_recommended$MONTH[i],",",
                                             sales_forecast_recommended$FORECASTED_SALES[i],")",sep=""))}
    print("Data Loading into AOL Table is completed Successfully")
  } else {
    print("Recommended Sales Forecast Output Result doesn't contain any Records")
  }
  
  
  ##################################################################################
  #################### Updating the AI Job Execution Summary 
  ##################################################################################
  
  aol_record_count <- dbGetQuery(mysql_db_connection,"select count(1) from AOL_Sales_Forecast")
  
  dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                                 SET AOL_RECORD_COUNT=",
                                                 aol_record_count,
                                                 " , JOB_RUN_STATUS=",
                                                 "'","AOL Data Load Completed","'",
                                                 " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))
  
  
  
  #######################################################################################
  ############## Conditional Execution End Statements
  #######################################################################################
  
} else {
  
  print("Source Query Result set doesn't have any Records")
  
  print("Please Check the Staging SQL Query in the Source Definition Table")
  
}

##################################################################################################
############  Closing the Active Connections and clearing the workspace if needed
#######################################################################################
end_time <- Sys.time()

execution_duration <- round(as.numeric(difftime(end_time, start_time,units="mins")),2)

cat("The Execution Time(in Minutes) for the Model is:", execution_duration)

##################################################################################
#################### Updating the AI Job Execution Summary 
##################################################################################

dbSendQuery(mysql_staging_db_connection,paste0("UPDATE AI_Jobs_Execution_Summary
                                               SET JOB_END_DATETIME=",
                                               "'",end_time,"'",
                                               " , JOB_DURATION=",execution_duration,
                                               " , JOB_RUN_STATUS=",
                                               "'","Completed","'",
                                               " , MODIFIED_DATETIME=",
                                               "'",end_time,"'",
                                               " WHERE RUN_ID=",new_AI_Job_RUN_ID,sep=""))

print("Disconnecting the open MYSQL Connections")
dbDisconnect(mysql_db_connection)
dbDisconnect(mysql_staging_db_connection) 
dbDisconnect(mysql_app_db_connection)

####### Turning off the Log Sinking
print("Closing the Log Sink Connection to the File")
sink()

#######################################################################################
##################################### End of the Code 
######################################################################################